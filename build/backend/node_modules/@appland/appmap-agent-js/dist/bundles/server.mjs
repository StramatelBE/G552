import { readFile as readFile$1, mkdir, writeFile } from 'node:fs/promises';
import { URL as URL$b, pathToFileURL, fileURLToPath, URLSearchParams } from 'node:url';
import { openSync, writeSync, readFileSync, readdirSync } from 'node:fs';
import { platform, tmpdir } from 'node:os';
import { win32, posix, join } from 'node:path';
import { spawnSync, spawn as spawn$1 } from 'node:child_process';
import Minimatch from 'minimatch';
import Treeify from 'treeify';
import AjvErrorTree from 'ajv-error-tree';
import { platform as platform$1, cwd } from 'node:process';
import * as Minimist from 'minimist';
import { createRequire } from 'node:module';
import { parse as parse$1 } from 'yaml';
import { clearTimeout, setTimeout as setTimeout$2 } from 'node:timers';
import { createServer, Socket } from 'node:net';
import NetSocketMessaging from 'net-socket-messaging';
import { createHash } from 'node:crypto';
import BabelParser from '@babel/parser';
import { createServer as createServer$1, request } from 'node:http';
import { Buffer } from 'node:buffer';
import { WebSocketServer } from 'ws';
import * as HtmlParser2 from 'htmlparser2';
import * as Astring from 'astring';
import { decode } from 'vlq';

const { decodeURIComponent: decodeURIComponent$1, encodeURIComponent: encodeURIComponent$1 } = globalThis;

const getDrive = (protocol, pathname) =>
  protocol.toLowerCase() === "file:"
    ? /^\/[a-zA-Z]:\//u.test(pathname)
      ? pathname[1].toLowerCase()
      : null
    : null;

const normalizeCase = (pathname, drive) =>
  drive === null ? pathname : pathname.toLowerCase();

const toAbsoluteUrl = (relative, base_url) =>
  new URL$b(
    /^[a-zA-Z]:\/[^/]/u.test(relative) ? `/${relative}` : relative,
    base_url,
  ).href;

const toRelativeUrl = (
  url,
  base_url,
  encodeSegment = encodeURIComponent$1,
) => {
  const { protocol, host, pathname, search, hash } = new URL$b(url);
  const {
    protocol: base_protocol,
    host: base_host,
    pathname: base_pathname,
  } = new URL$b(base_url);
  if (
    protocol.toLowerCase() !== base_protocol.toLowerCase() ||
    host.toLowerCase() !== base_host.toLowerCase()
  ) {
    return null;
  } else {
    const drive = getDrive(protocol, pathname);
    const base_drive = getDrive(base_protocol, base_pathname);
    if (drive !== base_drive) {
      return null;
    } else {
      const segments = normalizeCase(pathname, drive)
        .split("/")
        .map(decodeURIComponent$1);
      const base_segments = normalizeCase(base_pathname, base_drive)
        .split("/")
        .map(decodeURIComponent$1);
      base_segments.pop();
      while (
        segments.length > 0 &&
        base_segments.length > 0 &&
        segments[0] === base_segments[0]
      ) {
        segments.shift();
        base_segments.shift();
      }
      while (base_segments.length > 0) {
        base_segments.pop();
        segments.unshift("..");
      }
      if (segments.length > 0 && segments[0] !== "") {
        return `${segments.map(encodeSegment).join("/")}${search}${hash}`;
      } else {
        return `.${search}${hash}`;
      }
    }
  }
};

const toDirectoryUrl = (url) => {
  const url_obj = new URL$b(url);
  if (url_obj.pathname.endsWith("/")) {
    return url;
  } else {
    url_obj.pathname += "/";
    return url_obj.href;
  }
};

// Alternatively:
//   url.match(/:\/{0,2}.*\/([^/#]+)(#.*)?$/)[1]
const getUrlFilename = (url) => {
  const { pathname } = new URL$b(url);
  if (pathname === "" || pathname.endsWith("/")) {
    return null;
  } else {
    return pathname.substring(pathname.lastIndexOf("/") + 1);
  }
};

// Alternatively:
//   url.match(/([^.\/]+)(\.[^/#]*)(#.*)?$/)[1]
const getUrlBasename = (url) => {
  const filename = getUrlFilename(url);
  if (filename === null) {
    return null;
  } else if (filename.includes(".")) {
    return filename.substring(0, filename.indexOf("."));
  } else {
    return filename;
  }
};

// Alternatively:
//   url.match(/([^.\/]+)(\.[^/#]*)(#.*)?$/)[2]
const getUrlExtension = (url) => {
  const filename = getUrlFilename(url);
  if (filename === null) {
    return null;
  } else if (filename.includes(".")) {
    return filename.substring(filename.indexOf("."));
  } else {
    return null;
  }
};

const prefixDot = (string) => `.${string}`;

const getUrlExtensionArray = (url) => {
  const filename = getUrlFilename(url);
  if (filename === null) {
    return null;
  } else {
    const extensions = filename.split(".");
    extensions.shift();
    return extensions.map(prefixDot);
  }
};

// Alternatively:
//   url.match(/([^\/]+)(\.[^/#]*)(#.*)?$/)[2]
const getLastUrlExtension = (url) => {
  const filename = getUrlFilename(url);
  if (filename === null) {
    return null;
  } else if (filename.includes(".")) {
    return filename.substring(filename.lastIndexOf("."));
  } else {
    return null;
  }
};

// Consistent way to retreive home url in prod and test.

const {
  URL: URL$a,
  JSON: { parse: parseJSON$7 },
} = globalThis;

let url = toAbsoluteUrl(".", import.meta.url);

while (!url.endsWith("appmap-agent-js/")) {
  url = toAbsoluteUrl("..", url);
}

const self_directory = url;

const self_package = parseJSON$7(
  await readFile$1(
    new URL$a(toAbsoluteUrl("package.json", self_directory)),
    "utf8",
  ),
);

self_package.version;

const { Error: Error$9 } = globalThis;

class AppmapError extends Error$9 {}

class InternalAppmapError extends AppmapError {
  constructor(message) {
    super(message);
    this.name = "InternalAppmapError";
  }
}

class ExternalAppmapError extends AppmapError {
  constructor(message) {
    super(message);
    this.name = "ExternalAppmapError";
  }
}

const { Error: Error$8 } = globalThis;

class AssertionError extends Error$8 {
  constructor(message) {
    super(message);
    this.name = "AssertionError";
  }
}

const assert = (boolean, message, Constructor) => {
  if (!boolean) {
    throw new Constructor(message);
  }
};

const {
  Array,
  Math: { min },
} = globalThis;

const zip = (array1, array2) => {
  const length = min(array1.length, array2.length);
  const pairs = new Array(length);
  for (let index = 0; index < length; index += 1) {
    pairs[index] = [array1[index], array2[index]];
  }
  return pairs;
};

const {
  Boolean: Boolean$1,
  String: String$e,
  Number,
  parseInt: parseInt$4,
  Array: { isArray: isArray$4 },
  Number: {
    isNaN,
    NaN: NaN$1,
    NEGATIVE_INFINITY,
    POSITIVE_INFINITY,
    MAX_SAFE_INTEGER,
    MIN_SAFE_INTEGER,
  },
  Math: { round: round$1 },
  JSON: { stringify: stringifyJSON$7 },
} = globalThis;

const print = (any) => {
  if (typeof any === "function") {
    return "[function]";
  } else if (isArray$4(any)) {
    return "[array]";
  } else if (typeof any === "object" && any !== null) {
    return "[object]";
  } else if (typeof any === "string") {
    return stringifyJSON$7(any);
  } else {
    return String$e(any);
  }
};

const {
  Error: Error$7,
  String: String$d,
  JSON: { stringify: stringifyJSON$6 },
} = globalThis;

const format = (template, values) => {
  let index = 0;
  const { length } = values;
  const message = template.replace(
    /(%+)($|[^%])/gu,
    (_match, escape, marker) => {
      if (escape.length >= 2) {
        return `${escape.substring(1)}${marker}`;
      }
      assert(index < length, "missing format value", AssertionError);
      const value = values[index];
      index += 1;
      if (marker === "s") {
        assert(
          typeof value === "string",
          "expected a string for format",
          AssertionError,
        );
        return value;
      }
      if (marker === "f") {
        const print = value();
        assert(
          typeof print === "string",
          "expected a string as result",
          AssertionError,
        );
        return print;
      }
      if (marker === "j") {
        return stringifyJSON$6(value);
      }
      if (marker === "O") {
        try {
          return String$d(value);
        } catch {
          return print(value);
        }
      }
      if (marker === "o") {
        return print(value);
      }
      throw new Error$7("invalid format marker");
    },
  );
  assert(index === length, "missing format marker", AssertionError);
  return message;
};

const createCounter = (value) => ({ value });
const incrementCounter = (counter) => (counter.value += 1);

const {
  Error: Error$6,
  Reflect: { apply },
  WeakMap,
} = globalThis;

new WeakMap();

const noop = () => {};
const identity = (x) => x;
const constant = (x) => () => x;

// export const applySafe = (closure, context, inputs, log, recovery) => {
//   try {
//     return apply(closure, context, inputs);
//   } catch (error) {
//     log(error);
//     return recovery;
//   }
// };

const mapMaybe = (maybe, transform) =>
  maybe === null ? null : transform(maybe);

const recoverMaybe = (maybe, recovery) =>
  maybe === null ? recovery : maybe;

const {
  undefined: undefined$8,
  Object: Object$1,
  Reflect: { getOwnPropertyDescriptor: getOwnPropertyDescriptor$2, ownKeys: ownKeys$3, defineProperty: defineProperty$1 },
} = globalThis;

/* c8 ignore start */
const hasOwnProperty =
  getOwnPropertyDescriptor$2(Object$1, "hasOwn") === undefined$8
    ? (object, key) => getOwnPropertyDescriptor$2(object, key) !== undefined$8
    : Object$1.hasOwn;
/* c8 ignore stop */

const getOwnProperty = (object, key, _default) =>
  hasOwnProperty(object, key) ? object[key] : _default;

const coalesce = (value, key, _default) => {
  if (
    typeof value === "function" ||
    (typeof value === "object" && value !== null)
  ) {
    return getOwnProperty(value, key, _default);
  }
  return _default;
};

const coalesceCaseInsensitive = (value, key1, _default) => {
  if (
    typeof value === "function" ||
    (typeof value === "object" && value !== null)
  ) {
    key1 = key1.toLowerCase();
    for (const key2 of ownKeys$3(value)) {
      if (key2.toLowerCase() === key1) {
        return getOwnProperty(value, key2, _default);
      }
    }
  }
  return _default;
};

/* eslint-disable local/global-object-access */

const {
  undefined: undefined$7,
  ReferenceError,
  Reflect: { defineProperty },
} = globalThis;

const readGlobal = (name) => {
  if (hasOwnProperty(globalThis, name)) {
    return globalThis[name];
  } else {
    throw ReferenceError("missing global variable");
  }
};

// NB: Synchronous loggin is important to avoid infinite loop when async hooks are enabled.

const { URL: URL$9 } = globalThis;

const openLogFile = (specifier) => {
  if (typeof specifier === "number") {
    return specifier;
  } else if (typeof specifier === "string") {
    return openSync(new URL$9(specifier), "w");
  } else {
    throw new InternalAppmapError("invalid specifier type for log file");
  }
};

const generateLog$1 = (fd, name) => (message) => {
  writeSync(fd, `APPMAP-${name} ${message}\n`);
};

const makeLog = (specifier) => {
  const fd = openLogFile(specifier);
  return {
    logDebug: generateLog$1(fd, "DEBUG"),
    logInfo: generateLog$1(fd, "INFO"),
    logWarning: generateLog$1(fd, "WARNING"),
    logError: generateLog$1(fd, "ERROR"),
  };
};

const { logDebug: logDebug$1, logInfo: logInfo$1, logWarning: logWarning$1, logError: logError$1 } = makeLog(
  readGlobal("__APPMAP_LOG_FILE__"),
);

const levels = {
  debug: 1,
  info: 2,
  warning: 3,
  error: 4,
  off: 5,
};

const max_level = readGlobal("__APPMAP_LOG_LEVEL__");

assert(
  hasOwnProperty(levels, max_level),
  "invalid log level",
  InternalAppmapError,
);

const generateLog = (level, log) => {
  if (levels[level] < levels[max_level]) {
    return {
      log: noop,
      logWhen: noop,
      logAssert: assert,
    };
  } else {
    return {
      log: (template, ...rest) => {
        log(format(template, rest));
      },
      logWhen: (guard, template, ...rest) => {
        if (guard) {
          log(format(template, rest));
        }
        return guard;
      },
    };
  }
};

const { log: logDebug, logWhen: logDebugWhen } = generateLog(
  "debug",
  logDebug$1,
);

const { log: logInfo, logWhen: logInfoWhen } = generateLog(
  "info",
  logInfo$1,
);

const { log: logWarning, logWhen: logWarningWhen } = generateLog(
  "warning",
  logWarning$1,
);

const { log: logError, logWhen: logErrorWhen } = generateLog(
  "error",
  logError$1,
);

const {
  undefined: undefined$6,
  Reflect: { getOwnPropertyDescriptor: getOwnPropertyDescriptor$1 },
  Error: Error$5,
  Set: Set$5,
  /* c8 ignore start */
  Object: {
    hasOwn: hasOwn$1 = (obj, key) => getOwnPropertyDescriptor$1(obj, key) !== undefined$6,
  },
  /* c8 ignore stop */
} = globalThis;

const { resolve: resolvePath$1, relative: unresolvePath$1 } = win32;

const getBasename = (filename) =>
  filename.includes(".") ? filename.split(".")[0] : filename;

const forbidden = new Set$5([
  "CON",
  "PRN",
  "AUX",
  "NUL",
  "COM1",
  "COM2",
  "COM3",
  "COM4",
  "COM5",
  "COM6",
  "COM7",
  "COM8",
  "COM9",
  "LPT1",
  "LPT2",
  "LPT3",
  "LPT4",
  "LPT5",
  "LPT6",
  "LPT7",
  "LPT8",
  "LPT9",
]);

const sanitizePathFilename$2 = (filename) => {
  filename = filename.replace(/[\u0000-\u001F,\u0080-\u009F/?<>\\:*|"]/gu, "-");
  if (
    filename === "" ||
    filename.endsWith(".") ||
    filename.endsWith(" ") ||
    forbidden.has(getBasename(filename).toUpperCase())
  ) {
    filename = `_${filename}_`;
  }
  return filename;
};

const getShell$2 = (env) =>
  hasOwn$1(env, "COMSPEC") ? env.COMSPEC : "cmd.exe";

const ipc = "\\\\.\\pipe\\";

const toIpcPath$2 = (path) => `${ipc}${path}`;

const fromIpcPath$2 = (path) => {
  if (path.startsWith(ipc)) {
    return path.substring(ipc.length);
  } else {
    throw new Error$5("not an ipc path");
  }
};

const toDirectoryPath$2 = (path) =>
  path.endsWith("/") || path.endsWith("\\") ? path : `${path}\\`;

const toAbsolutePath$2 = (relative, base) => {
  const path =
    base.endsWith("/") || base.endsWith("\\")
      ? resolvePath$1(base, relative)
      : resolvePath$1(base, "..", relative);
  return relative.endsWith("/") || relative.endsWith("\\") ? `${path}\\` : path;
};

const toRelativePath$2 = (path, base) => {
  const relative = unresolvePath$1(
    base.endsWith("/") || base.endsWith("\\") ? base : `${base}\\..`,
    path,
  );
  if (relative === "") {
    return ".";
  } else if (path.endsWith("/") || path.endsWith("\\")) {
    return `${relative}\\`;
  } else {
    return relative;
  }
};

const getPathFilename$2 = (path) => {
  const parts = /[\\/]([^\\/]*)$/u.exec(path);
  if (parts === null) {
    return null;
  } else {
    const filename = parts[1];
    return filename === "" ? null : filename;
  }
};

var Win32 = /*#__PURE__*/Object.freeze({
  __proto__: null,
  sanitizePathFilename: sanitizePathFilename$2,
  getShell: getShell$2,
  toIpcPath: toIpcPath$2,
  fromIpcPath: fromIpcPath$2,
  toDirectoryPath: toDirectoryPath$2,
  toAbsolutePath: toAbsolutePath$2,
  toRelativePath: toRelativePath$2,
  getPathFilename: getPathFilename$2
});

const {
  undefined: undefined$5,
  Reflect: { getOwnPropertyDescriptor },
  /* c8 ignore start */
  Object: {
    hasOwn = (obj, key) => getOwnPropertyDescriptor(obj, key) !== undefined$5,
  },
  /* c8 ignore stop */
} = globalThis;

const { resolve: resolvePath, relative: unresolvePath } = posix;

const sanitizePathFilename$1 = (filename) =>
  // Escape `.` and `..`
  /^\.*$/u.test(filename)
    ? `...${filename}`
    : filename.replace(/\\/gu, "\\\\").replace(/\//gu, "\\");

const getShell$1 = (env) => (hasOwn(env, "SHELL") ? env.SHELL : "/bin/sh");

const toIpcPath$1 = (path) => path;

const fromIpcPath$1 = (path) => path;

const toDirectoryPath$1 = (path) =>
  path.endsWith("/") ? path : `${path}/`;

const toAbsolutePath$1 = (relative, base) => {
  const path = base.endsWith("/")
    ? resolvePath(base, relative)
    : resolvePath(base, "..", relative);
  return relative.endsWith("/") ? `${path}/` : path;
};

const toRelativePath$1 = (path, base) => {
  const relative = unresolvePath(
    base.endsWith("/") ? base : `${base}/..`,
    path,
  );
  if (relative === "") {
    return ".";
  } else if (path.endsWith("/")) {
    return `${relative}/`;
  } else {
    return relative;
  }
};

const getPathFilename$1 = (path) => {
  const segments = path.split("/");
  const filename = segments[segments.length - 1];
  return filename === "" ? null : filename;
};

var Posix = /*#__PURE__*/Object.freeze({
  __proto__: null,
  sanitizePathFilename: sanitizePathFilename$1,
  getShell: getShell$1,
  toIpcPath: toIpcPath$1,
  fromIpcPath: fromIpcPath$1,
  toDirectoryPath: toDirectoryPath$1,
  toAbsolutePath: toAbsolutePath$1,
  toRelativePath: toRelativePath$1,
  getPathFilename: getPathFilename$1
});

const convertPathToFileUrl = (path) =>
  pathToFileURL(path).href;

/* c8 ignore start */
const {
  getPathFilename,
  // This function convert an arbitrary string to a valid platform-specific filename.
  // For instance, it replaces path separator.
  sanitizePathFilename,
  getShell,
  toIpcPath,
  fromIpcPath,
  toDirectoryPath,
  toAbsolutePath,
  toRelativePath,
} = platform() === "win32" ? Win32 : Posix;

const {
  URL: URL$8,
  JSON: { parse: parseJSON$6 },
} = globalThis;

//////////////////////////////
// extractRepositoryPackage //
//////////////////////////////

const readPackage = (url) => {
  try {
    return {
      url,
      content: readFileSync(new URL$8("package.json", url), "utf8"),
    };
  } catch (error) {
    logWarning("Cannot read package.json file at %j >> %O", url, error);
    return null;
  }
};

const parsePackage = ({ url, content }) => {
  try {
    return {
      url,
      data: parseJSON$6(content),
    };
  } catch (error) {
    logWarning("Cannot parse package.json file at %j >> %O", url, error);
    return null;
  }
};

const summarizePackage = ({ url, data }) => {
  const { name, version, homepage } = {
    name: null,
    version: null,
    homepage: null,
    ...data,
  };
  if (typeof name !== "string") {
    logWarning(
      "Invalid type for name property in package.json file at %j, got: %j",
      url,
      name,
    );
    return null;
  } else if (typeof version !== "string") {
    logWarning(
      "Invalid type for version property in package.json file at %j, got %j",
      url,
      version,
    );
    return null;
  } else {
    return {
      name,
      version,
      homepage: typeof homepage === "string" ? homepage : null,
    };
  }
};

const extractRepositoryPackage = (url) =>
  mapMaybe(mapMaybe(readPackage(url), parsePackage), summarizePackage);

const { URL: URL$7 } = globalThis;

const spawn = (exec, argv, url) => {
  const result = spawnSync(exec, argv, {
    cwd: fileURLToPath(new URL$7(".", url)),
    encoding: "utf8",
    timeout: 1000,
    stdio: ["ignore", "pipe", "pipe"],
  });
  const error = coalesce(result, "error", null);
  assert(
    !logErrorWhen(
      error !== null,
      "Executable %j with argv %j on cwd %j threw an error >> %O",
      exec,
      argv,
      url,
      error,
    ),
    "Failed to spawn executable",
    ExternalAppmapError,
  );
  const { signal, status, stdout, stderr } = result;
  assert(
    !logErrorWhen(
      signal !== null,
      "Executable %j with argv %j on cwd %j was killed with %j",
      exec,
      argv,
      url,
      signal,
    ),
    "Command exit with unexpected kill signal",
    ExternalAppmapError,
  );
  if (status === 0) {
    return stdout.trim();
  } else {
    logWarning(
      "Executable %j with argv %j on cwd %j failed with %j >> %s",
      exec,
      argv,
      url,
      status,
      stderr,
    );
    return null;
  }
};

const { URL: URL$6, parseInt: parseInt$3 } = globalThis;

const trim = (string) => string.trim();

const parseStatus = (stdout) => stdout.split("\n").map(trim);

const parseDescription = (stdout) => {
  const parts = /^([^-]*)-([0-9]+)-/u.exec(stdout);
  /* c8 ignore start */
  if (parts === null) {
    logWarning("Failed to parse git description %j", stdout);
    return 0;
  }
  /* c8 ignore stop */
  return parseInt$3(parts[2], 10);
};

const readRepository = (url) => {
  try {
    return readdirSync(new URL$6(url));
  } catch (error) {
    logError("Could not read repository directory %j >> %O", url, error);
    throw new ExternalAppmapError("Could not read repository directory");
  }
};

const extractRepositoryHistory = (url) => {
  if (readRepository(url).includes(".git")) {
    return {
      repository: spawn("git", ["config", "--get", "remote.origin.url"], url),
      branch: spawn("git", ["rev-parse", "--abbrev-ref", "HEAD"], url),
      commit: spawn("git", ["rev-parse", "HEAD"], url),
      status: mapMaybe(
        spawn("git", ["status", "--porcelain"], url),
        parseStatus,
      ),
      tag: spawn("git", ["describe", "--abbrev=0", "--tags"], url),
      annotated_tag: spawn("git", ["describe", "--abbrev=0"], url),
      commits_since_tag: mapMaybe(
        spawn("git", ["describe", "--long", "--tags"], url),
        parseDescription,
      ),
      commits_since_annotated_tag: mapMaybe(
        spawn("git", ["describe", "--long"], url),
        parseDescription,
      ),
    };
  } else {
    logWarning("Repository directory %j is not a git directory", url);
    return null;
  }
};

const { Minimatch: MinimatchClass } = Minimatch;

const compileGlob = (glob) => new MinimatchClass(glob).makeRe();

const { Map: Map$9, RegExp: RegExp$3 } = globalThis;

const regexps = new Map$9();

const makeRegExp = (source, flags) => {
  try {
    return new RegExp$3(source, flags);
  } catch (error) {
    logError(
      "Failed to compile regexp source %j with flags %j >> %O",
      source,
      flags,
      error,
    );
    throw new ExternalAppmapError("Failed to compile matcher regexp");
  }
};

const makeRegExpCache = (source, flags) => {
  const key = `/${source}/${flags}`;
  if (regexps.has(key)) {
    return regexps.get(key);
  } else {
    const regexp = makeRegExp(source, flags);
    regexps.set(key, regexp);
    return regexp;
  }
};

const escape = (char) => `\\${char}`;

const sanitizeForRegExp = (string) =>
  string.replace(/[/\\+*?.^$()[\]{}|]/gu, escape);

// const sanitizeForGlob = (string) => string.replace(/[*?[\]]/g, escape);

const toTargetRegExp = (target, recursive) => {
  if (recursive) {
    if (target.endsWith("/")) {
      return `^${sanitizeForRegExp(target)}`;
    } else {
      return `^${sanitizeForRegExp(target)}(/|$)`;
    }
  } else {
    if (target.endsWith("/")) {
      return `^${sanitizeForRegExp(target)}[^/]*$`;
    } else {
      return `^${sanitizeForRegExp(target)}$`;
    }
  }
};

const createMatcher = (options, base) => {
  const {
    glob,
    url,
    path,
    dist,
    regexp,
    flags,
    recursive,
    external,
    relative,
  } = {
    glob: null,
    path: null,
    url: null,
    dist: null,
    regexp: null,
    flags: "",
    recursive: true,
    external: false,
    relative: true,
    ...options,
  };
  if (regexp !== null) {
    return {
      base: relative ? base : null,
      source: regexp,
      flags,
    };
  }
  if (glob !== null) {
    const { source, flags } = compileGlob(glob);
    return {
      base,
      source,
      flags,
    };
  }
  if (path !== null) {
    return {
      base,
      source: toTargetRegExp(path, recursive),
      flags: "",
    };
  }
  if (url !== null) {
    return {
      base: null,
      source: toTargetRegExp(url, recursive),
      flags: "",
    };
  }
  if (dist !== null) {
    assert(
      dist[dist.length - 1] !== "/",
      "package path should not end with a path separator",
      InternalAppmapError,
    );
    let source = `node_modules/${sanitizeForRegExp(dist)}/`;
    if (!external) {
      source = `^${source}`;
    }
    if (!recursive) {
      source = `${source}[^/]*$`;
    }
    return {
      base,
      source,
      flags: "",
    };
  }
  throw new InternalAppmapError("invalid matcher options");
};

// We escape as few character as possible to hide the fact that configuration fields are urls rather than paths.
const escaping = {
  __proto__: null,
  "/": "%2F",
  "?": "%3F",
  "#": "%23",
};

const escapeCharacter = (match) => escaping[match];

const escapeSegment = (segment) => segment.replace(/[/#?]/gu, escapeCharacter);

const matchUrl = (matcher, url) => {
  const { base, source, flags } = matcher;
  if (base === null) {
    const matched = makeRegExpCache(source, flags).test(url);
    logDebug(
      "url %j %s absolute regexp matcher %j with flags %j",
      url,
      matched ? "matched" : "did not match",
      source,
      flags,
    );
    return matched;
  } else {
    const relative = toRelativeUrl(url, base, escapeSegment);
    if (relative === null) {
      logDebug(
        "could not apply matcher %j because %j cannot be expressed relatively to %j, will treat it as not matched",
        source,
        url,
        base,
      );
      return false;
    } else {
      const matched = makeRegExpCache(source, flags).test(relative);
      logDebug(
        "url %j which resolves to %j relatively to %j %s relative regexp matcher %j with flags %j",
        url,
        relative,
        base,
        matched ? "matched" : "did not match",
        source,
        flags,
      );
      return matched;
    }
  }
};

const lookupUrl = (entries, url, default_value) => {
  for (const [matcher, value] of entries) {
    if (matchUrl(matcher, url)) {
      return value;
    }
  }
  return default_value;
};

const { URL: URL$5 } = globalThis;

const {
  validateSerial: validateAjvSerial,
  validatePayload: validateAjvPayload,
  validateExternalConfiguration: validateAjvExternalConfiguration,
  validateInternalConfiguration: validateAjvInternalConfiguration,
  validateMessage: validateAjvMessage,
  validateSourceMap: validateAjvSourceMap,
} = await import(new URL$5("dist/schema.mjs", self_directory));

const { asTree } = Treeify;

const generateValidate = (validateAjv, name, AppmapError) => (json) => {
  if (!validateAjv(json)) {
    const { errors } = validateAjv;
    const { length } = errors;
    assert(length > 0, "unexpected empty error array", InternalAppmapError);
    const tree1 = AjvErrorTree.structureAJVErrorArray(errors);
    const tree2 = AjvErrorTree.summarizeAJVErrorTree(tree1);
    logError(
      "invalid %s\n%s\n  Parameters = %j\n  Input = %j",
      name,
      typeof tree2 === "string" ? tree2 : asTree(tree2, true),
      errors.map((error) => coalesce(error, "params", null)),
      json,
    );
    throw new AppmapError("Failed to validate data against JSON schema");
  }
};

const validateMessage = generateValidate(
  validateAjvMessage,
  "message",
  InternalAppmapError,
);

const validateExternalConfiguration = generateValidate(
  validateAjvExternalConfiguration,
  "user-defined configuration",
  ExternalAppmapError,
);

const validateSourceMap = generateValidate(
  validateAjvSourceMap,
  "source-map",
  ExternalAppmapError,
);

const {
  Array: { isArray: isArray$3 },
  Reflect: { ownKeys: ownKeys$2 },
  Object: { entries: toEntries$5 },
} = globalThis;

const HOOK_APPLY_GLOBAL = "APPMAP_HOOK_APPLY";

const HOOK_EVAL_GLOBAL = "APPMAP_HOOK_EVAL";

const EXPECTED_EXTRA_PROPERTIES = ["test_recording"];

////////////
// Extend //
////////////

const assign = (value1, value2) => ({ ...value1, ...value2 });

const overwrite = (_value1, value2) => value2;

// const append = (value1, value2) => [...value1, ...value2];

const prepend = (value1, value2) => [...value2, ...value1];

const extendCommandOptions = (options1, options2) => ({
  ...options1,
  ...options2,
  env: {
    ...coalesce(options1, "env", {}),
    ...coalesce(options2, "env", {}),
  },
});

///////////////
// Normalize //
///////////////

const normalizeDefaultProcess = (default_process, _base) => {
  if (typeof default_process === "boolean") {
    return { enabled: default_process };
  } else {
    return {
      enabled: false,
      ...default_process,
    };
  }
};

const normalizeExclusion = (exclusion, _base) => {
  if (typeof exclusion === "string") {
    exclusion = {
      "qualified-name": exclusion,
      recursive: true,
    };
  }
  const default_value = coalesce(exclusion, "combinator", "and") === "and";
  return {
    combinator: "and",
    "qualified-name": default_value,
    name: default_value,
    "every-label": default_value,
    "some-label": default_value,
    excluded: true,
    recursive: false,
    ...exclusion,
  };
};

const normalizeCommandOptions = (options, base) => ({
  shell: false,
  encoding: "utf8",
  env: {},
  stdio: "inherit",
  timeout: 0,
  killSignal: "SIGTERM",
  ...options,
  cwd: hasOwnProperty(options, "cwd")
    ? toDirectoryUrl(toAbsoluteUrl(options.cwd, base))
    : toAbsoluteUrl(".", base),
});

const normalizeHooks = (hooks, _base) => {
  if (hasOwnProperty(hooks, "eval")) {
    hooks.eval =
      typeof hooks.eval === "boolean"
        ? {
            hidden: HOOK_EVAL_GLOBAL,
            aliases: hooks.eval ? ["eval"] : [],
          }
        : hooks.eval;
  }
  if (hasOwnProperty(hooks, "apply")) {
    hooks.apply =
      typeof hooks.apply === "boolean"
        ? hooks.apply
          ? HOOK_APPLY_GLOBAL
          : null
        : hooks.apply;
  }
  return hooks;
};

const normalizeDefaultPackage = (package_, _base) => {
  if (typeof package_ === "boolean") {
    package_ = { enabled: package_ };
  }
  return {
    enabled: true,
    shallow: false,
    exclude: [],
    "inline-source": null,
    "source-type": null,
    parsing: null,
    ...package_,
  };
};

const normalizeAgent = ({ directory, package: _package }, base) => ({
  directory: toDirectoryUrl(toAbsoluteUrl(directory, base)),
  package: _package,
});

const normalizeDirectoryUrl = (url, base) =>
  toDirectoryUrl(toAbsoluteUrl(url, base));

const normalizeExclude = (exclusions, _base) =>
  exclusions.map(normalizeExclusion);

const normalizeCommand = (command, _base) => ({
  source: typeof command === "string" ? command : null,
  tokens: typeof command === "string" ? null : command,
});

const normalizeScenarios = (scenarios, base) =>
  toEntries$5(scenarios).map(([key, value]) => ({
    base,
    key,
    value,
  }));

const normalizeLog = (log, base) => {
  if (typeof log === "string") {
    log = { level: log };
  }
  if (hasOwnProperty(log, "file") && typeof log.file !== "number") {
    log.file = toAbsoluteUrl(log.file, base);
  }
  return log;
};

const normalizePort = (port, base) => {
  if (typeof port === "string" && port !== "") {
    port = toAbsoluteUrl(port, base);
  }
  return port;
};

const generateNormalizeSplit = (separator, key1, key2) => (value) => {
  if (typeof value === "string") {
    const segments = value.split(separator);
    return {
      [key1]: segments[0],
      [key2]: segments.length === 1 ? null : segments[1],
    };
  }
  return value;
};

const normalizeRecording = generateNormalizeSplit(
  ".",
  "defined-class",
  "method-id",
);

const normalizeFramework = generateNormalizeSplit("@", "name", "version");

const normalizeFrameworkArray = (frameworks) =>
  frameworks.map(normalizeFramework);

const normalizePackageMatcher = (matcher, base) => {
  if (typeof matcher === "string") {
    matcher = { glob: matcher };
  }
  const {
    enabled,
    shallow,
    "inline-source": inline_source,
    exclude,
    "source-type": source_type,
    parsing,
    ...rest
  } = {
    enabled: true,
    "inline-source": null,
    shallow: hasOwnProperty(matcher, "dist"),
    exclude: [],
    "source-type": null,
    parsing: null,
    ...matcher,
  };
  return [
    createMatcher(rest, base),
    {
      enabled,
      "inline-source": inline_source,
      shallow,
      exclude: exclude.map(normalizeExclusion),
      "source-type": source_type,
      parsing,
    },
  ];
};

const normalizePackageMatcherArray = (matchers, base) => {
  if (!isArray$3(matchers)) {
    matchers = [matchers];
  }
  return matchers.map((matcher) => normalizePackageMatcher(matcher, base));
};

const normalizeProcessMatcher = (matcher, base) => {
  if (typeof matcher === "string") {
    matcher = { glob: matcher };
  }
  const { enabled, ...rest } = {
    enabled: true,
    ...matcher,
  };
  return [createMatcher(rest, base), { enabled }];
};

const normalizeProcesseMatcherArray = (matchers, base) => {
  if (!isArray$3(matchers)) {
    matchers = [matchers];
  }
  return matchers.map((matcher) => normalizeProcessMatcher(matcher, base));
};

////////////
// fields //
////////////

const fields = {
  socket: {
    extend: overwrite,
    normalize: identity,
  },
  heartbeat: {
    extend: overwrite,
    normalize: identity,
  },
  threshold: {
    extend: overwrite,
    normalize: identity,
  },
  agent: {
    extend: overwrite,
    normalize: normalizeAgent,
  },
  repository: {
    extend: overwrite,
    normalize: identity,
  },
  scenario: {
    extend: overwrite,
    normalize: identity,
  },
  scenarios: {
    extend: overwrite,
    normalize: normalizeScenarios,
  },
  "recursive-process-recording": {
    extend: overwrite,
    normalize: identity,
  },
  "postmortem-function-exclusion": {
    extend: overwrite,
    normalize: identity,
  },
  command: {
    extend: overwrite,
    normalize: normalizeCommand,
  },
  "command-win32": {
    extend: overwrite,
    normalize: normalizeCommand,
  },
  "command-options": {
    extend: extendCommandOptions,
    normalize: normalizeCommandOptions,
  },
  validate: {
    extend: assign,
    normalize: identity,
  },
  log: {
    extend: assign,
    normalize: normalizeLog,
  },
  host: {
    extend: overwrite,
    normalize: identity,
  },
  session: {
    extend: overwrite,
    normalize: identity,
  },
  sessions: {
    extend: overwrite,
    normalize: identity,
  },
  "proxy-port": {
    extend: overwrite,
    normalize: identity,
  },
  "trace-port": {
    extend: overwrite,
    normalize: normalizePort,
  },
  "http-switch": {
    extend: overwrite,
    normalize: identity,
  },
  "trace-protocol": {
    extend: overwrite,
    normalize: identity,
  },
  "track-port": {
    extend: overwrite,
    normalize: normalizePort,
  },
  "track-protocol": {
    extend: overwrite,
    normalize: identity,
  },
  "intercept-track-port": {
    extend: overwrite,
    normalize: identity,
  },
  "intercept-track-protocol": {
    extend: overwrite,
    normalize: identity,
  },
  enabled: {
    extend: overwrite,
    normalize: identity,
  },
  "default-process": {
    extend: overwrite,
    normalize: normalizeDefaultProcess,
  },
  processes: {
    extend: prepend,
    normalize: normalizeProcesseMatcherArray,
  },
  recorder: {
    extend: overwrite,
    normalize: identity,
  },
  "inline-source": {
    extend: overwrite,
    normalize: identity,
  },
  hooks: {
    extend: assign,
    normalize: normalizeHooks,
  },
  ordering: {
    extend: overwrite,
    normalize: identity,
  },
  "collapse-package-hierachy": {
    extend: overwrite,
    normalize: identity,
  },
  serialization: {
    extend: assign,
    normalize: identity,
  },
  main: {
    extend: overwrite,
    normalize: toAbsoluteUrl,
  },
  language: {
    extend: overwrite,
    normalize: identity,
  },
  engine: {
    extend: overwrite,
    normalize: identity,
  },
  "default-package": {
    extend: overwrite,
    normalize: normalizeDefaultPackage,
  },
  packages: {
    extend: prepend,
    normalize: normalizePackageMatcherArray,
  },
  exclude: {
    extend: prepend,
    normalize: normalizeExclude,
  },
  recording: {
    extend: overwrite,
    normalize: normalizeRecording,
  },
  appmap_dir: {
    extend: overwrite,
    normalize: normalizeDirectoryUrl,
  },
  appmap_file: {
    extend: overwrite,
    normalize: identity,
  },
  name: {
    extend: overwrite,
    normalize: identity,
  },
  "map-name": {
    extend: overwrite,
    normalize: identity,
  },
  pruning: {
    extend: overwrite,
    normalize: identity,
  },
  labels: {
    extend: prepend,
    normalize: identity,
  },
  feature: {
    extend: overwrite,
    normalize: identity,
    initial: null,
  },
  "feature-group": {
    extend: overwrite,
    normalize: identity,
  },
  frameworks: {
    extend: prepend,
    normalize: normalizeFrameworkArray,
  },
};

const extendConfiguration = (
  internal_configuration,
  external_configuration,
  base,
) => {
  const extended_internal_configuration = { ...internal_configuration };
  validateExternalConfiguration(external_configuration);
  for (const key of ownKeys$2(external_configuration)) {
    if (hasOwnProperty(fields, key)) {
      const { normalize, extend } = fields[key];
      extended_internal_configuration[key] = extend(
        extended_internal_configuration[key],
        normalize(external_configuration[key], base),
      );
    } else {
      logInfoWhen(
        !EXPECTED_EXTRA_PROPERTIES.includes(key),
        "Configuration property not recognized by the agent: %j",
        key,
      );
    }
  }
  return extended_internal_configuration;
};

const {
  RegExp: RegExp$2,
  Object: { entries: toEntries$4 },
} = globalThis;

const resolveConfigurationRepository = (configuration) => {
  assert(
    configuration.agent === null,
    "duplicate respository resolution",
    InternalAppmapError,
  );
  const { directory } = configuration.repository;
  const { name, version, homepage } = self_package;
  return extendConfiguration(
    configuration,
    {
      agent: {
        directory: self_directory,
        package: { name, version, homepage },
      },
      repository: {
        directory,
        history: extractRepositoryHistory(directory),
        package: extractRepositoryPackage(directory),
      },
    },
    directory,
  );
};

const extendConfigurationPort = (configuration, ports) => {
  for (const [key, new_port] of toEntries$4(ports)) {
    const { [key]: old_port } = configuration;
    if (old_port === 0 || old_port === "") {
      assert(
        typeof new_port === typeof old_port,
        "port type mismatch",
        InternalAppmapError,
      );
      configuration = extendConfiguration(
        configuration,
        { [key]: new_port },
        configuration.repository.directory,
      );
    } else {
      assert(old_port === new_port, "port mismatch", InternalAppmapError);
    }
  }
  return configuration;
};

const compileScenario = (scenario) => {
  try {
    return new RegExp$2(scenario, "u");
  } catch (error) {
    logError(
      "Scenario configuration field is not a valid regexp: %j >> %O",
      scenario,
      error,
    );
    throw new ExternalAppmapError("Scenario is not a regexp");
  }
};

const getConfigurationScenarios = (configuration) => {
  const { scenarios, scenario } = configuration;
  const regexp = compileScenario(scenario);
  return scenarios
    .filter(({ key }) => regexp.test(key))
    .map(({ base, value }) =>
      extendConfiguration(configuration, { scenarios: {}, ...value }, base),
    );
};

// NODE_OPTIONS format is not platform-specific
// It is also not well documented but it seems to only require whitespace escaping.
// - https://github.com/nodejs/node/issues/12971
// - https://github.com/nodejs/node/commit/2eb627301c1f6681ec51f43b84e37f3908514853
// - https://nodejs.org/api/cli.html#node_optionsoptions
// - https://github.com/nodejs/node/blob/80270994d6ba6019a6a74adc1b97a0cc1bd343ed/src/node_options.cc
const escapeNodeOption = (token) => {
  assert(
    !token.includes(" "),
    "spaces should have been percent-encoded",
    InternalAppmapError,
  );
  return token;
};

const resolveShell = (shell, env) => {
  if (shell === false) {
    return null;
  } else if (shell === true) {
    return getShell(env);
  } else {
    return shell;
  }
};

const space = /^\s$/u;

const tokenizeShell = (source) => {
  const tokens = [];
  let token = "";
  let escaped = false;
  let quote = null;
  for (const char of source) {
    token += char;
    if (quote === "'") {
      if (char === "'") {
        quote = null;
      }
    } else if (escaped) {
      escaped = false;
    } else if (char === "\\") {
      escaped = true;
    } else if (quote === '"') {
      if (char === '"') {
        quote = null;
      }
    } else if (space.test(char)) {
      if (token.length > 1) {
        tokens.push(token.substring(0, token.length - 1));
      }
      token = "";
    } else if (char === '"' || char === "'") {
      quote = char;
    }
  }
  if (token !== "") {
    tokens.push(token);
  }
  assert(
    !logErrorWhen(quote !== null, "unterminated quote on command %s", source),
    "unterminated quote on command",
    ExternalAppmapError,
  );
  assert(
    !logErrorWhen(escaped, "missing escaped character on command %s", source),
    "missing escaped character",
    ExternalAppmapError,
  );
  return tokens;
};

// https://github.com/nodejs/node/blob/e58ed6d855e1af6579aaa50471426db8881eea99/lib/child_process.js#L628
const tokenize = (source, shell) => {
  if (shell === null) {
    return tokenizeShell(source);
  } else if (/^(?:.*\\)?cmd(?:\.exe)?$/iu.test(shell)) {
    return [shell, "/d", "/s", "/c", `"${source}"`];
  } else {
    return [shell, "-c", source];
  }
};

const isPrefixArray = (prefix, array) => {
  const { length } = prefix;
  if (length > array.length) {
    return false;
  } else {
    for (let index = 0; index < length; index += 1) {
      if (prefix[index] !== array[index]) {
        return false;
      }
    }
    return true;
  }
};

const findScriptIndex = (tokens, index) => {
  if (index < tokens.length) {
    const token = tokens[index];
    // In the node cli, `-` indicates that the script
    // is read from the stdin. In that case, we should
    // not return any index. For instance:
    // `node - foo.js`
    if (token === "-") {
      return null;
      // In the CLI of node, npm and npx: `--` indicates
      // the the script argument is following.
    } else if (token === "--") {
      return index + 1 < tokens.length ? index + 1 : null;
      // We only support named argument of the form
      // `--foo=bar` and not `--foo bar`.
    } else if (token.startsWith("-")) {
      return findScriptIndex(tokens, index + 1);
    } else {
      return index;
    }
  } else {
    return null;
  }
};

const executables = [
  ["node"],
  ["npm", "exec"],
  ["npm.cmd", "exec"],
  ["npm", "x"],
  ["npm.cmd", "x"],
  ["npx"],
  ["npx.cmd"],
  ["yarn", "exec"],
  ["yarn.cmd", "exec"],
  ["yarn", "node"],
  ["yarn.cmd", "node"],
  [],
];

const splitTokens = (tokens) => {
  const executable = executables.find((executable) =>
    isPrefixArray(executable, tokens),
  );
  const positional = findScriptIndex(tokens, executable.length);
  assert(
    !logErrorWhen(
      positional === null,
      "could not parse and hook command because of missing positional argument, got %j",
      tokens,
    ),
    "could not parse and hook command",
    ExternalAppmapError,
  );
  return {
    __proto__: null,
    exec: tokens.slice(0, positional + 1),
    argv: tokens.slice(positional + 1),
  };
};

const sniffTokens = (tokens, name) => {
  const executable = executables.find((executable) =>
    isPrefixArray(executable, tokens),
  );
  const positional = findScriptIndex(tokens, executable.length);
  return positional !== null && tokens[positional].includes(name);
};

const name$5 = "mocha";
const recursive$5 = null;

const doesSupport$7 = (tokens) => sniffTokens(tokens, "mocha");

const hookCommandAsync$5 = (tokens, self, _base) => {
  const { exec, argv } = splitTokens(tokens);
  return [
    ...exec,
    "--require",
    fileURLToPath(toAbsoluteUrl("lib/node/mocha-hook.mjs", self)),
    ...argv,
  ];
};

const hookEnvironment$5 = (env, self, _base) => ({
  ...env,
  NODE_OPTIONS: `${coalesce(
    env,
    "NODE_OPTIONS",
    "",
  )} --experimental-loader=${escapeNodeOption(
    toAbsoluteUrl("lib/node/recorder.mjs", self),
  )}`,
});

var MochaRecorder = /*#__PURE__*/Object.freeze({
  __proto__: null,
  name: name$5,
  recursive: recursive$5,
  doesSupport: doesSupport$7,
  hookCommandAsync: hookCommandAsync$5,
  hookEnvironment: hookEnvironment$5
});

const {
  URL: URL$4,
  JSON: { parse: parseJson },
} = globalThis;

const loadJsonAsync = async (url) =>
  parseJson(await readFile$1(new URL$4(url), "utf8"));

const loadYamlAsync = async (url) =>
  parse$1(await readFile$1(new URL$4(url), "utf8"));

const loaders = {
  ".json": loadJsonAsync,
  ".yaml": loadYamlAsync,
  ".yml": loadYamlAsync,
};

const loadAsync = async (url) => {
  const extension = getLastUrlExtension(url);
  if (hasOwnProperty(loaders, extension)) {
    return await loaders[extension](url);
  } else {
    // Can load both cjs and esm modules
    // cf: https://nodejs.org/api/packages.html#packagejson-and-file-extensions
    // Currently, we do not support typescript.
    return (await import(url)).default;
  }
};

const isLoadMissingError = (error) =>
  hasOwnProperty(error, "code") &&
  (error.code === "ENOENT" ||
    error.code === "ERR_MODULE_NOT_FOUND" ||
    error.code === "MODULE_NOT_FOUND");

const {
  URL: URL$3,
  JSON: { parse: parseJSON$5 },
} = globalThis;

const loadConfigFileAsync = async (url, strict) => {
  try {
    return await loadAsync(url);
  } catch (error) {
    if (!strict && isLoadMissingError(error)) {
      return null;
    } else {
      logError(
        "Failed to load jest configuration file at %j >> %O",
        url,
        error,
      );
      throw new ExternalAppmapError("Failed to load jest configuration file");
    }
  }
};

const loadPackageJsonAsync = async (directory) => {
  try {
    return parseJSON$5(
      await readFile$1(
        new URL$3(toAbsoluteUrl("package.json", directory)),
        "utf8",
      ),
    );
  } catch (error) {
    if (hasOwnProperty(error, "code") && error.code === "ENOENT") {
      return null;
    } else {
      logError("Could not load package.json from %j >> %O", directory, error);
      throw new ExternalAppmapError("Could not load package.json");
    }
  }
};

const loadJestConfigAsync = async (options, { root, base }) => {
  if (hasOwnProperty(options, "config")) {
    return await loadConfigFileAsync(toAbsoluteUrl(options.config, base), true);
  } else {
    const { jest: maybe_package_config } = {
      jest: null,
      ...(await loadPackageJsonAsync(root)),
    };
    if (maybe_package_config !== null) {
      return maybe_package_config;
    } else {
      for (const extension of [".ts", ".js", ".cjs", ".mjs", ".json"]) {
        const maybe_config = await loadConfigFileAsync(
          toAbsoluteUrl(`jest.config${extension}`, root),
          false,
        );
        if (maybe_config !== null) {
          return maybe_config;
        }
      }
      return {};
    }
  }
};

const PRESET_FILE_NAME_ARRAY = [
  "jest-preset.json",
  "jest-preset.js",
  "jest-preset.cjs",
  "jest-preset.mjs",
];

const resolvePresetSpecifier = (specifier, root) => {
  if (specifier.startsWith("./") || specifier.startsWith("../")) {
    return toAbsoluteUrl(specifier, root);
  } else {
    const { resolve } = createRequire(new URL$3(root));
    for (const filename of PRESET_FILE_NAME_ARRAY) {
      const sub_specifier = `${specifier}/${filename}`;
      try {
        return convertPathToFileUrl(resolve(sub_specifier));
      } catch (error) {
        logDebug(
          "Could not resolve jest preset at %j >> %O",
          sub_specifier,
          error,
        );
      }
    }
    logError("Could not resolve jest preset at %j", specifier);
    throw new ExternalAppmapError("Could not resolve jest preset");
  }
};

const resolveJestPresetAsync = async (config, root) => {
  if (hasOwnProperty(config, "preset")) {
    return {
      ...(await loadConfigFileAsync(
        resolvePresetSpecifier(config.preset, root),
        true,
      )),
      ...config,
      preset: null,
    };
  } else {
    return config;
  }
};

const {
  JSON: { stringify: stringifyJSON$5, parse: parseJSON$4 },
  Object: { entries: toEntries$3, fromEntries: fromEntries$1 },
  Array: { isArray: isArray$2 },
} = globalThis;

const { default: minimist } = Minimist;

const hook = fileURLToPath(
  toAbsoluteUrl("lib/node/transformer-jest.mjs", self_directory),
);

const extractTransformEntryValue = (value) => {
  if (typeof value === "string") {
    return { specifier: value, options: {} };
  } else {
    assert(
      !logErrorWhen(
        !isArray$2(value) || value.length !== 2 || typeof value[0] !== "string",
        "Invalid transform field, expected transform field to be either a string or an array of length two whose first element is a string: %j",
        value,
      ),
      "Invalid transform field",
      ExternalAppmapError,
    );
    return { specifier: value[0], options: value[1] };
  }
};

const compileHookTransformEntry = (root) => {
  const replacement = constant(fileURLToPath(root));
  return ([key, value]) => {
    const { specifier, options } = extractTransformEntryValue(value);
    return [
      key,
      {
        specifier: specifier.replace(/<rootDir>\//gu, replacement),
        options,
      },
    ];
  };
};

const hookTransformObject = (transform, root) => ({
  "^": [
    hook,
    fromEntries$1(toEntries$3(transform).map(compileHookTransformEntry(root))),
  ],
});

const hookJestArgvAsync = async (argv, base) => {
  if (!argv.includes("--no-cache")) {
    argv = ["--no-cache", ...argv];
  }
  const options = minimist(argv);
  const root = hasOwnProperty(options, "rootDir")
    ? toDirectoryUrl(toAbsoluteUrl(options.rootDir, base))
    : base;
  if (hasOwnProperty(options, "transform")) {
    const index = argv.indexOf("--transform");
    assert(
      !logErrorWhen(
        index !== argv.lastIndexOf("--transform"),
        "Jest `--transform` argument should not be duplicate: %j",
        argv,
      ),
      "Jest --transform argument should not be duplicate",
      ExternalAppmapError,
    );
    assert(
      !logErrorWhen(
        index === argv.length - 1,
        "Jest `--transform` argument should not be in last postion: %j",
        argv,
      ),
      "Jest `--transform` argument should not be in last postion",
      ExternalAppmapError,
    );
    let transform = argv[index + 1];
    try {
      transform = parseJSON$4(transform);
    } catch (error) {
      logError(
        "Jest `--transform` argument should be a json string: %j >> %O",
        transform,
        error,
      );
      throw new ExternalAppmapError(
        "Jest --transform argument should be a json string",
      );
    }
    return [
      ...argv.slice(0, index + 1),
      stringifyJSON$5(hookTransformObject(transform, root)),
      ...argv.slice(index + 2, argv.length),
    ];
  } else {
    const config = await resolveJestPresetAsync(
      await loadJestConfigAsync(options, { root, base }),
      root,
    );
    const transform = hasOwnProperty(config, "transform")
      ? config.transform
      : // Default jest transformer.
        // cf: https://jestjs.io/docs/code-transformation#defaults
        // Unfortunately `require("jest-config").defaults.transform` is undefined
        { "\\.[jt]sx?$": "babel-jest" };
    return [
      ...argv,
      "--transform",
      stringifyJSON$5(hookTransformObject(transform, root)),
    ];
  }
};

const name$4 = "jest";
const recursive$4 = null;

const doesSupport$6 = (tokens) => sniffTokens(tokens, "jest");

const hookCommandAsync$4 = async (tokens, self, base) => {
  const { exec, argv } = splitTokens(tokens);
  return [
    ...exec,
    ...(await hookJestArgvAsync(argv, base)),
    "--setupFilesAfterEnv",
    fileURLToPath(toAbsoluteUrl("lib/node/recorder.mjs", self)),
  ];
};

const hookEnvironment$4 = (env, self, _base) => ({
  ...env,
  NODE_OPTIONS: `${coalesce(
    env,
    "NODE_OPTIONS",
    "",
  )} --experimental-vm-modules --experimental-loader=${escapeNodeOption(
    toAbsoluteUrl("lib/node/loader-esm.mjs", self),
  )}`,
});

var JestRecorder = /*#__PURE__*/Object.freeze({
  __proto__: null,
  name: name$4,
  recursive: recursive$4,
  doesSupport: doesSupport$6,
  hookCommandAsync: hookCommandAsync$4,
  hookEnvironment: hookEnvironment$4
});

const doesSupport$5 = (tokens) =>
  tokens.length > 0 && tokens[0].startsWith("node");

const splitNodeCommand = (tokens) => {
  assert(
    !logErrorWhen(
      !doesSupport$5(tokens),
      "Could not recognize %j as a node command",
      tokens,
    ),
    "Not a parsed node command",
    ExternalAppmapError,
  );
  return {
    exec: tokens.slice(0, 1),
    argv: tokens.slice(1),
  };
};

const generateNodeRecorder$1 = (recorder) => ({
  doesSupport: doesSupport$5,
  recursive: false,
  name: recorder,
  hookCommandAsync: (tokens, self, _base) => {
    const { exec, argv } = splitNodeCommand(tokens);
    return [
      ...exec,
      "--experimental-loader",
      toAbsoluteUrl(`lib/node/recorder.mjs`, self),
      ...argv,
    ];
  },
  hookEnvironment: (env, _self, _base) => env,
});

const {
  name: name$3,
  recursive: recursive$3,
  doesSupport: doesSupport$4,
  hookCommandAsync: hookCommandAsync$3,
  hookEnvironment: hookEnvironment$3,
} = generateNodeRecorder$1("process");

var ProcessRecorder = /*#__PURE__*/Object.freeze({
  __proto__: null,
  name: name$3,
  recursive: recursive$3,
  doesSupport: doesSupport$4,
  hookCommandAsync: hookCommandAsync$3,
  hookEnvironment: hookEnvironment$3
});

const doesSupport$3 = constant(true);

const generateNodeRecorder = (recorder) => ({
  name: recorder,
  recursive: true,
  doesSupport: doesSupport$3,
  hookCommandAsync: (tokens, _self, _base) => tokens,
  hookEnvironment: (env, self, _base) => ({
    ...env,
    NODE_OPTIONS: `${coalesce(
      env,
      "NODE_OPTIONS",
      "",
    )} --experimental-loader=${escapeNodeOption(
      toAbsoluteUrl(`lib/node/recorder.mjs`, self),
    )}`,
  }),
});

const {
  name: name$2,
  recursive: recursive$2,
  doesSupport: doesSupport$2,
  hookCommandAsync: hookCommandAsync$2,
  hookEnvironment: hookEnvironment$2,
} = generateNodeRecorder("process");

var ProcessRecorderRecursive = /*#__PURE__*/Object.freeze({
  __proto__: null,
  name: name$2,
  recursive: recursive$2,
  doesSupport: doesSupport$2,
  hookCommandAsync: hookCommandAsync$2,
  hookEnvironment: hookEnvironment$2
});

const {
  name: name$1,
  recursive: recursive$1,
  doesSupport: doesSupport$1,
  hookCommandAsync: hookCommandAsync$1,
  hookEnvironment: hookEnvironment$1,
} = generateNodeRecorder$1("remote");

var RemoteRecorder = /*#__PURE__*/Object.freeze({
  __proto__: null,
  name: name$1,
  recursive: recursive$1,
  doesSupport: doesSupport$1,
  hookCommandAsync: hookCommandAsync$1,
  hookEnvironment: hookEnvironment$1
});

const {
  name,
  recursive,
  doesSupport,
  hookCommandAsync,
  hookEnvironment,
} = generateNodeRecorder("remote");

var RemoteRecorderRecursive = /*#__PURE__*/Object.freeze({
  __proto__: null,
  name: name,
  recursive: recursive,
  doesSupport: doesSupport,
  hookCommandAsync: hookCommandAsync,
  hookEnvironment: hookEnvironment
});

const Recorders = [
  MochaRecorder,
  JestRecorder,
  ProcessRecorder,
  ProcessRecorderRecursive,
  RemoteRecorder,
  RemoteRecorderRecursive,
];

const {
  JSON: { stringify: stringifyJSON$4 },
} = globalThis;

const platform_command_key = `command-${platform$1}`;

const pickPlatformSpecificCommand = (configuration) => {
  if (
    hasOwnProperty(configuration, platform_command_key) &&
    configuration[platform_command_key] !== null
  ) {
    return {
      ...configuration,
      command: configuration[platform_command_key],
    };
  } else {
    return configuration;
  }
};

const resolveConfigurationAutomatedRecorder = (configuration, env) => {
  assert(
    configuration.command !== null,
    "missing command in configuration",
    InternalAppmapError,
  );
  let {
    "recursive-process-recording": recursive,
    recorder,
    command: { source, tokens },
    "command-options": options,
  } = configuration;
  logWarningWhen(
    tokens !== null && options.shell !== false,
    "Tokenized commands (%j) are directly spawned so the provided shell (%j) is a no-op",
    tokens,
    options.shell,
  );
  if (tokens === null) {
    assert(
      source !== "null",
      "either command.tokens or command.source should be defined",
      InternalAppmapError,
    );
    tokens = tokenize(source, resolveShell(options.shell, env));
  }
  if (recorder === null) {
    recorder = "process";
    for (const Recorder of Recorders) {
      if (Recorder.recursive === recursive || Recorder.recursive === null) {
        if (Recorder.doesSupport(tokens)) {
          recorder = Recorder.name;
          break;
        }
      }
    }
  }
  return extendConfiguration(
    configuration,
    {
      recorder,
      command: tokens,
      "command-options": {
        ...options,
        shell: false,
      },
    },
    configuration.repository.directory,
  );
};

const compileConfigurationCommandAsync = async (configuration, env) => {
  assert(
    configuration.agent !== null,
    "missing agent in configuration",
    InternalAppmapError,
  );
  assert(
    configuration.command !== null,
    "missing command in configuration",
    InternalAppmapError,
  );
  assert(
    configuration.command.tokens !== null,
    "command should have been tokenized",
    InternalAppmapError,
  );
  const {
    "recursive-process-recording": recursive,
    recorder,
    agent: { directory: self },
    command: { tokens },
    "command-options": options,
  } = configuration;
  env = {
    ...env,
    ...options.env,
    APPMAP_CONFIGURATION: stringifyJSON$4(configuration),
  };
  const { hookCommandAsync, hookEnvironment } = Recorders.find(
    ({ recursive: recorder_recursive, name }) =>
      (recorder_recursive === null || recorder_recursive === recursive) &&
      name === recorder,
  );
  const [exec, ...argv] = await hookCommandAsync(tokens, self, options.cwd);
  return {
    exec,
    argv,
    options: {
      ...options,
      env: hookEnvironment(env, self, options.cwd),
    },
  };
};

const { Set: Set$4 } = globalThis;

const createPool = () => ({
  timer: null,
  sockets: new Set$4(),
});

const addPool = (pool, socket) => {
  pool.sockets.add(socket);
  socket.on("close", () => {
    pool.sockets.delete(socket);
    if (pool.sockets.size === 0 && pool.timer !== null) {
      clearTimeout(pool.timer);
      pool.timer = null;
    }
  });
};

const closePool = (pool, delay) => {
  if (delay === 0) {
    for (const socket of pool.sockets) {
      socket.destroy();
    }
    clearTimeout(pool.timer);
    pool.timer = null;
  } else {
    for (const socket of pool.sockets) {
      socket.end();
    }
    pool.timer = setTimeout$2(closePool, delay, pool, 0);
  }
};

const {
  Date: { now },
  Math: { random },
} = globalThis;

const getUuid = () =>
  `${now().toString(32).substr(-4)}${random().toString(32).substr(-4)}`;

const convertPort = (port) => {
  if (typeof port === "string") {
    if (port === "") {
      return toIpcPath(join(tmpdir(), getUuid()));
    } else {
      return toIpcPath(fileURLToPath(port));
    }
  } else if (typeof port === "number") {
    return port;
  } else {
    throw new InternalAppmapError("invalid port");
  }
};

const revertPort = (address) => {
  if (typeof address === "string") {
    return convertPathToFileUrl(fromIpcPath(address));
  } else if (
    typeof address === "object" &&
    hasOwnProperty(address, "port") &&
    typeof address.port === "number"
  ) {
    return address.port;
  } else {
    throw new InternalAppmapError("invalid address");
  }
};

const START = "TR?";
const STOP = "TR!";
const ERROR = "ERR";
const SOURCE = "SRC";
const BEGIN_REQUEST_AMEND = "RQ.";

const SESSION_ASSIGNMENT = "SE!";

const GROUP_DEFINITION = "GR?";
const GROUP_ASSIGNMENT = "GR!";

const BEGIN_BUNDLE_EVENT = "BD>";
const END_BUNDLE_EVENT = "BD<";

const BEFORE_JUMP_EVENT = "JP?";
const AFTER_JUMP_EVENT = "JP!";

const BEGIN_APPLY_EVENT = "APP";
const END_RETURN_EVENT = "RET";
const END_THROW_EVENT = "TRW";

const BEFORE_AWAIT_EVENT = "AWT";
const BEFORE_YIELD_EVENT = "YLD";
const AFTER_RESOLVE_EVENT = "RES";
const AFTER_REJECT_EVENT = "REJ";

const BEGIN_REQUEST_EVENT = "RQ>";
const END_RESPONSE_EVENT = "RS<";
const BEFORE_REQUEST_EVENT = "RQ?";
const AFTER_RESPONSE_EVENT = "RS!";

const BEFORE_QUERY_EVENT = "QRY";
const AFTER_ANSWER_EVENT = "ASW";

const BUNDLE_PAYLOAD = { type: "bundle" };
const JUMP_PAYLOAD = { type: "jump" };

/////////////
// inflate //
/////////////

const inflaters = {
  __proto__: null,
  // not event //
  [START]: (_session, _group, [_head, track, configuration]) => ({
    type: "start",
    track,
    configuration,
  }),
  [STOP]: (_session, _group, [_head, track, termination]) => ({
    type: "stop",
    track,
    termination,
  }),
  [SOURCE]: (_session, _group, [_head, url, content]) => ({
    type: "source",
    url,
    content,
  }),
  [ERROR]: (session, _group, [_head, error]) => ({
    type: "error",
    session,
    error,
  }),
  [GROUP_DEFINITION]: (
    session,
    _group,
    [_head, group, child, description],
  ) => ({
    type: "group",
    session,
    group,
    child,
    description,
  }),
  [BEGIN_REQUEST_AMEND]: (
    session,
    _group,
    [_head, tab, protocol, method, url, route, headers, body],
  ) => ({
    type: "amend",
    site: "begin",
    session,
    tab,
    payload: {
      type: "request",
      side: "server",
      protocol,
      method,
      url,
      route,
      headers,
      body,
    },
  }),
  // bundle //
  [BEGIN_BUNDLE_EVENT]: (session, group, [_head, tab, time]) => ({
    type: "event",
    site: "begin",
    session,
    group,
    tab,
    time,
    payload: BUNDLE_PAYLOAD,
  }),
  [END_BUNDLE_EVENT]: (session, group, [_head, tab, time]) => ({
    type: "event",
    site: "end",
    session,
    group,
    tab,
    time,
    payload: BUNDLE_PAYLOAD,
  }),
  // jump //
  [BEFORE_JUMP_EVENT]: (session, group, [_head, tab, time]) => ({
    type: "event",
    site: "before",
    session,
    group,
    tab,
    time,
    payload: JUMP_PAYLOAD,
  }),
  [AFTER_JUMP_EVENT]: (session, group, [_head, tab, time]) => ({
    type: "event",
    site: "after",
    session,
    group,
    tab,
    time,
    payload: JUMP_PAYLOAD,
  }),
  // apply //
  [BEGIN_APPLY_EVENT]: (
    session,
    group,
    [_head, tab, time, function_, this_, arguments_],
  ) => ({
    type: "event",
    site: "begin",
    session,
    group,
    tab,
    time,
    payload: {
      type: "apply",
      function: function_,
      this: this_,
      arguments: arguments_,
    },
  }),
  [END_RETURN_EVENT]: (
    session,
    group,
    [_head, tab, time, function_, result],
  ) => ({
    type: "event",
    site: "end",
    session,
    group,
    tab,
    time,
    payload: {
      type: "return",
      function: function_,
      result,
    },
  }),
  [END_THROW_EVENT]: (
    session,
    group,
    [_head, tab, time, function_, error],
  ) => ({
    type: "event",
    site: "end",
    session,
    group,
    tab,
    time,
    payload: {
      type: "throw",
      function: function_,
      error,
    },
  }),
  // await/yield //
  [BEFORE_AWAIT_EVENT]: (session, group, [_head, tab, time, promise]) => ({
    type: "event",
    site: "before",
    session,
    group,
    tab,
    time,
    payload: {
      type: "await",
      promise,
    },
  }),
  [BEFORE_YIELD_EVENT]: (session, group, [_head, tab, time, iterator]) => ({
    type: "event",
    site: "before",
    session,
    group,
    tab,
    time,
    payload: {
      type: "yield",
      iterator,
    },
  }),
  [AFTER_RESOLVE_EVENT]: (session, group, [_head, tab, time, result]) => ({
    type: "event",
    site: "after",
    session,
    group,
    tab,
    time,
    payload: {
      type: "resolve",
      result,
    },
  }),
  [AFTER_REJECT_EVENT]: (session, group, [_head, tab, time, error]) => ({
    type: "event",
    site: "after",
    session,
    group,
    tab,
    time,
    payload: {
      type: "reject",
      error,
    },
  }),
  // http-server //
  [BEGIN_REQUEST_EVENT]: (
    session,
    group,
    [_head, tab, time, protocol, method, url, route, headers, body],
  ) => ({
    type: "event",
    site: "begin",
    session,
    group,
    tab,
    time,
    payload: {
      type: "request",
      side: "server",
      protocol,
      method,
      url,
      route,
      headers,
      body,
    },
  }),
  [END_RESPONSE_EVENT]: (
    session,
    group,
    [_head, tab, time, status, message, headers, body],
  ) => ({
    type: "event",
    site: "end",
    session,
    group,
    tab,
    time,
    payload: {
      type: "response",
      side: "server",
      status,
      message,
      headers,
      body,
    },
  }),
  // http-client //
  [BEFORE_REQUEST_EVENT]: (
    session,
    group,
    [_head, tab, time, protocol, method, url, route, headers, body],
  ) => ({
    type: "event",
    site: "before",
    session,
    group,
    tab,
    time,
    payload: {
      type: "request",
      side: "client",
      protocol,
      method,
      url,
      route,
      headers,
      body,
    },
  }),
  [AFTER_RESPONSE_EVENT]: (
    session,
    group,
    [_head, tab, time, status, message, headers, body],
  ) => ({
    type: "event",
    site: "after",
    session,
    group,
    tab,
    time,
    payload: {
      type: "response",
      side: "client",
      status,
      message,
      headers,
      body,
    },
  }),
  // query //
  [BEFORE_QUERY_EVENT]: (
    session,
    group,
    [_head, tab, time, database, version, sql, parameters],
  ) => ({
    type: "event",
    site: "before",
    session,
    group,
    tab,
    time,
    payload: {
      type: "query",
      database,
      version,
      sql,
      parameters,
    },
  }),
  [AFTER_ANSWER_EVENT]: (session, group, [_head, tab, time]) => ({
    type: "event",
    site: "after",
    session,
    group,
    tab,
    time,
    payload: { type: "answer" },
  }),
};

const inflate = (lines) => {
  let group = null;
  let session = null;
  const messages = [];
  for (const tokens of lines) {
    const head = tokens[0];
    if (head === SESSION_ASSIGNMENT) {
      session = tokens[1];
    } else if (head === GROUP_ASSIGNMENT) {
      group = tokens[1];
    } else {
      messages.push(inflaters[head](session, group, tokens));
    }
  }
  return messages;
};

const digest = (string) => {
  const hash = createHash("sha256");
  hash.update(string, "utf8");
  return hash.digest("base64");
};

const version = "1.8.0";

let validate = null;

const validateAppmap = (data) => {
  if (validate === null) {
    // Dynamic import on demand for performance
    const require = createRequire(import.meta.url);
    ({ validate } = require("@appland/appmap-validate"));
  }
  try {
    validate(data, { version });
  } catch (error) {
    logError("Invalid %s appmap >> %O\n>>%j", version, error, data);
    throw new InternalAppmapError("Invalid appmap");
  }
};

const { String: String$c, parseInt: parseInt$2, undefined: undefined$4 } = globalThis;

const regexp = /^([A-Za-z0-9+/=]+\|)?([\s\S]+):([0-9]+):([0-9]+)$/u;

const stringifyLocation = ({
  url,
  hash,
  position: { line, column },
}) => {
  if (hash === null) {
    return `${url}:${String$c(line)}:${String$c(column)}`;
  } else {
    return `${hash}|${url}:${String$c(line)}:${String$c(column)}`;
  }
};

const parseLocation = (string) => {
  const parts = regexp.exec(string);
  assert(parts !== null, "invalid location format", InternalAppmapError);
  return {
    hash:
      parts[1] === undefined$4
        ? null
        : parts[1].substring(0, parts[1].length - 1),
    url: parts[2],
    position: {
      line: parseInt$2(parts[3]),
      column: parseInt$2(parts[4]),
    },
  };
};

const { parse: parseBabel } = BabelParser;

// const getPredecessorComment = (code, index, comments) => {
//   index -= 1;
//   while (index > 0) {
//     if (comments.has(index)) {
//       return comments.get(index);
//     }
//     if (!/^\p{Zs}$/u.test(code[index])) {
//       break;
//     }
//     index -= 1;
//   }
//   return null;
// };

const printComment = ({ type, value }) => {
  if (type === "CommentBlock") {
    return `/*${value}*/`;
  } else if (type === "CommentLine") {
    return `//${value}`;
  } /* c8 ignore start */ else {
    throw new InternalAppmapError("invalid comment type");
  } /* c8 ignore stop */
};

const getLeadingCommentArray = (node) =>
  coalesce(node, "leadingComments", []);

const trimStartString = (string) => string.trimStart();

const extractLineLabel = (line) => {
  assert(line.startsWith("@label "), "invalid label line", InternalAppmapError);
  const maybe_tokens = line.substring("@label".length).match(/\s+\S+/gu);
  return maybe_tokens === null ? [] : maybe_tokens.map(trimStartString);
};

const extractCommentLabelArray = ({ value: text }) => {
  const maybe_lines = text.match(/@label .*/gu);
  return maybe_lines === null ? [] : maybe_lines.flatMap(extractLineLabel);
};

const resolveSource = (source, { url }) => {
  if (source === null) {
    const extension = getLastUrlExtension(url);
    if (extension === ".cjs" || extension === ".cts" || extension === ".node") {
      return "script";
    } else if (extension === ".mjs" || extension === ".mts") {
      return "module";
    } else {
      return "unambiguous";
    }
  } else {
    return source;
  }
};

const resolvePluginArray = (plugins, { url, content }) => {
  if (plugins === null) {
    const extensions = getUrlExtensionArray(url);
    const plugins = [];
    if (extensions.includes(".jsx")) {
      plugins.push(["jsx", {}]);
    }
    if (
      extensions.includes(".ts") ||
      extensions.includes(".mts") ||
      extensions.includes(".cts")
    ) {
      plugins.push(["typescript", {}]);
    }
    if (
      extensions.includes(".tsx") ||
      extensions.includes(".mtsx") ||
      extensions.includes(".ctsx")
    ) {
      plugins.push(["jsx", {}], ["typescript", {}]);
    }
    if (
      extensions.includes(".flow") ||
      /^[ \t\n]*\/(\/[ \t]*|\*[ \t\n]*)@flow/u.test(content)
    ) {
      plugins.push(["flow", {}]);
    }
    return plugins;
  } else {
    return plugins;
  }
};

const parseSafe = ({ url, content }, options) => {
  try {
    return parseBabel(content, options);
  } catch (error) {
    logError("Unrecoverable parsing error at file %j >> %O", url, error);
    const { sourceType: source_type } = options;
    return {
      errors: [],
      program: {
        type: "Program",
        body: [],
        sourceType: source_type === "unambiguous" ? "script" : source_type,
        loc: {
          start: { line: 0, column: 0 },
          end: { line: 0, column: 0 },
          filename: url,
        },
      },
    };
  }
};

const parseEstree = (file, { source, plugins }) => {
  const { url } = file;
  const { errors, program: node } = parseSafe(file, {
    sourceFilename: url,
    sourceType: resolveSource(source, file),
    plugins: [
      ["estree", { classFeatures: true }],
      ...resolvePluginArray(plugins, file),
    ],
    errorRecovery: true,
    attachComment: true,
  });
  for (const error of errors) {
    logWarning("Recoverable parsing error at file %j >> %O", url, error);
  }
  return node;
};

const {
  String: String$b,
  parseInt: parseInt$1,
  Infinity,
  Math: { abs },
} = globalThis;

const stringifyPosition = ({ line, column }) =>
  `${String$b(line)}:${String$b(column)}`;

const parsePosition = (string) => {
  const parts = /^([0-9]+):([0-9]+)$/u.exec(string);
  assert(parts !== null, "invalid position format", InternalAppmapError);
  return {
    line: parseInt$1(parts[1]),
    column: parseInt$1(parts[2]),
  };
};

const measurePositionDistance = (
  { line: line1, column: column1 },
  { line: line2, column: column2 },
  { line_weight, column_weight },
) => line_weight * abs(line2 - line1) + column_weight * abs(column2 - column1);

const resolvePosition = (map, position1, options) => {
  const key1 = stringifyPosition(position1);
  if (map.has(key1)) {
    return position1;
  } else {
    let best_distance = Infinity;
    let best_position = null;
    for (const key2 of map.keys()) {
      const position2 = parsePosition(key2);
      const distance = measurePositionDistance(position1, position2, options);
      if (distance < best_distance) {
        best_distance = distance;
        best_position = position2;
      }
    }
    const { threshold } = options;
    return best_distance <= threshold ? best_position : null;
  }
};

/* eslint-disable no-use-before-define */

const {
  Object: { entries: toEntries$2 },
  Array: { isArray: isArray$1 },
} = globalThis;

const ANONYMOUS = "[anonymous]";

const DYNAMIC = "[dynamic]";

const getBoundary = ({ start, end }) => ({ start, end });

const getHead = ({ head }) => head;

const getRest = ({ rest }) => rest;

const combine = (results) => ({
  head: results.flatMap(getHead),
  rest: results.flatMap(getRest),
});

const isContainerNodeType = (type) =>
  type === "FunctionExpression" ||
  type === "FunctionDeclaration" ||
  type === "ArrowFunctionExpression" ||
  type === "ClassExpression" ||
  type === "ClassDeclaration" ||
  type === "ObjectExpression";

const getContainerName = (node, name) => {
  if (node.type === "FunctionExpression" || node.type === "ClassExpression") {
    return name === ANONYMOUS && node.id !== null ? node.id.name : name;
  } else if (
    node.type === "FunctionDeclaration" ||
    node.type === "ClassDeclaration"
  ) {
    return node.id === null ? "default" : node.id.name;
  } else if (
    node.type === "ArrowFunctionExpression" ||
    node.type === "ObjectExpression"
  ) {
    return name;
  } /* c8 ignore start */ else {
    throw new InternalAppmapError("invalid container node");
  } /* c8 ignore stop */
};

/////////////
// factory //
/////////////

const createFileEntity = (name, children, node) => ({
  type: "file",
  excluded: false,
  labels: getLeadingCommentArray(node).flatMap(extractCommentLabelArray),
  name,
  children,
});

const createClassEntity = (name, children, node) => ({
  type: "class",
  excluded: false,
  labels: getLeadingCommentArray(node).flatMap(extractCommentLabelArray),
  name,
  children,
});

const createClosureEntity = (name, children, node, is_static) => {
  const comments = getLeadingCommentArray(node);
  return {
    type: "closure",
    excluded: false,
    name,
    children,
    used: false,
    static: is_static,
    comments,
    labels: comments.flatMap(extractCommentLabelArray),
    parameters: node.params.map(getBoundary),
    boundary: getBoundary(node),
    position: { ...node.loc.start }, // cleanup prototype
  };
};

/////////////
// visitor //
/////////////

const visitProgram = (node, name) => {
  if (node.type === "Program") {
    return createFileEntity(
      name,
      node.body.flatMap((child) => visitNode$1(child, ANONYMOUS)),
      node,
    );
  } /* c8 ignore start */ else {
    throw new InternalAppmapError("invalid program node");
  } /* c8 ignore stop */
};

const visitAny = (any) => {
  if (isArray$1(any)) {
    return any.flatMap(visitAny);
  } else if (
    typeof any === "object" &&
    any !== null &&
    hasOwnProperty(any, "type") &&
    typeof any.type === "string"
  ) {
    return visitNode$1(any, ANONYMOUS);
  } else {
    return [];
  }
};

const visitContainerNode = (node, name) => {
  if (
    node.type === "FunctionExpression" ||
    node.type === "FunctionDeclaration" ||
    node.type === "ArrowFunctionExpression"
  ) {
    return {
      head: [
        createClosureEntity(
          getContainerName(node, name),
          [
            ...node.params.flatMap((child) => visitNode$1(child, ANONYMOUS)),
            ...visitNode$1(node.body, ANONYMOUS),
          ],
          node,
          false,
        ),
      ],
      rest: [],
    };
  } else if (
    node.type === "ClassExpression" ||
    node.type === "ClassDeclaration"
  ) {
    const { head, rest } = visitClassBody(node.body);
    return {
      head: [createClassEntity(getContainerName(node, name), head, node)],
      rest: [
        ...(node.superClass === null
          ? []
          : visitNode$1(node.superClass, ANONYMOUS)),
        ...rest,
      ],
    };
  } else if (node.type === "ObjectExpression") {
    const { head, rest } = combine(node.properties.map(visitObjectProperty));
    return {
      head: [createClassEntity(getContainerName(node, name), head, node)],
      rest,
    };
  } /* c8 ignore start */ else {
    throw new InternalAppmapError("invalid container node type");
  } /* c8 ignore stop */
};

const visitEntry = ([key, value]) => {
  if (key === "type" || key === "start" || key === "end" || key === "loc") {
    return [];
  } else {
    return visitAny(value);
  }
};

const visitNode$1 = (node, name) => {
  if (node.type === "AssignmentExpression") {
    return [
      ...visitNode$1(node.left, ANONYMOUS),
      ...visitNode$1(
        node.right,
        node.left.type === "Identifier" ? node.left.name : ANONYMOUS,
      ),
    ];
  } else if (node.type === "VariableDeclarator") {
    return [
      ...visitNode$1(node.id, ANONYMOUS),
      ...(node.init === null
        ? []
        : visitNode$1(
            node.init,
            node.id.type === "Identifier" ? node.id.name : ANONYMOUS,
          )),
    ];
  } else if (node.type === "ConditionalExpression") {
    return [
      ...visitNode$1(node.test, ANONYMOUS),
      ...visitNode$1(node.consequent, name),
      ...visitNode$1(node.alternate, name),
    ];
  } else if (node.type === "SequenceExpression") {
    const children = node.expressions.slice();
    const last_child = children.pop();
    return [
      ...children.flatMap((child) => visitNode$1(child, ANONYMOUS)),
      ...visitNode$1(last_child, name),
    ];
  } else if (node.type === "LogicalExpression") {
    return [...visitNode$1(node.left, name), ...visitNode$1(node.right, name)];
  } else if (isContainerNodeType(node.type)) {
    const { head, rest } = visitContainerNode(node, name);
    return [...head, ...rest];
  } else {
    return toEntries$2(node).flatMap(visitEntry);
  }
};

const visitClassBody = (node) => {
  if (node.type === "ClassBody") {
    return combine(node.body.map(visitClassProperty));
  } /* c8 ignore start */ else {
    logWarning("unrecognized class body node %j", node.type);
    return {
      head: [],
      rest: visitNode$1(node, ANONYMOUS),
    };
  } /* c8 ignore stop */
};

const visitClassProperty = (node) => {
  if (node.type === "MethodDefinition") {
    return {
      rest: visitNode$1(node.key, ANONYMOUS),
      head: visitClassMethod(
        node.value,
        !node.computed && node.key.type === "Identifier"
          ? node.key.name
          : DYNAMIC,
        node.static,
      ),
    };
  } else if (node.type === "PropertyDefinition") {
    return combine([
      { head: [], rest: visitNode$1(node.key, ANONYMOUS) },
      node.value === null
        ? { head: [], rest: [] }
        : visitPropertyValue(
            node.value,
            !node.computed && node.key.type === "Identifier"
              ? node.key.name
              : DYNAMIC,
          ),
    ]);
  } /* c8 ignore start */ else {
    logWarning("unrecognized class property node %j", node.type);
    return {
      head: [],
      rest: visitNode$1(node, ANONYMOUS),
    };
  } /* c8 ignore stop */
};

const visitClassMethod = (node, name, is_static) => {
  if (node.type === "FunctionExpression") {
    return createClosureEntity(
      name,
      [
        ...node.params.flatMap((child) => visitNode$1(child, ANONYMOUS)),
        .../* typescript abstract method */
        (hasOwnProperty(node, "body") && node.body !== null
          ? visitNode$1(node.body, ANONYMOUS)
          : []),
      ],
      node,
      is_static,
    );
  } /* c8 ignore start */ else {
    logWarning("unrecognized class method node %j", node.type);
    return {
      head: [],
      rest: visitNode$1(node, ANONYMOUS),
    };
  } /* c8 ignore stop */
};

const visitObjectProperty = (node) => {
  if (node.type === "Property") {
    return combine([
      { head: [], rest: visitNode$1(node.key, ANONYMOUS) },
      visitPropertyValue(
        node.value,
        !node.computed && node.key.type === "Identifier"
          ? node.key.name
          : DYNAMIC,
      ),
    ]);
  } else if (node.type === "SpreadElement") {
    return {
      head: [],
      rest: visitNode$1(node.argument, ANONYMOUS),
    };
  } /* c8 ignore start */ else {
    logWarning("unrecognized object property node %j", node.type);
    return {
      head: [],
      rest: visitNode$1(node, ANONYMOUS),
    };
  } /* c8 ignore stop */
};

const visitPropertyValue = (node, name) => {
  if (node.type === "LogicalExpression") {
    return combine([
      visitPropertyValue(node.left, name),
      visitPropertyValue(node.right, name),
    ]);
  } else if (node.type === "ConditionalExpression") {
    return combine([
      { head: [], rest: visitNode$1(node.test, ANONYMOUS) },
      visitPropertyValue(node.consequent, name),
      visitPropertyValue(node.alternate, name),
    ]);
  } else if (node.type === "SequenceExpression") {
    const children = node.expressions.slice();
    const last_child = children.pop();
    return combine([
      {
        head: [],
        rest: children.flatMap((child) => visitNode$1(child, ANONYMOUS)),
      },
      visitPropertyValue(last_child, name),
    ]);
  } else if (isContainerNodeType(node.type)) {
    return visitContainerNode(node, name);
  } else {
    return {
      head: [],
      rest: visitNode$1(node, ANONYMOUS),
    };
  }
};

////////////
// export //
////////////

const toEntity = visitProgram;

const {
  RegExp: RegExp$1,
  Object: { entries: toEntries$1 },
} = globalThis;

const compileClause = ([name, pattern]) => {
  if (typeof pattern === "boolean") {
    return (_node, _naming) => pattern;
  } else if (typeof pattern === "string") {
    const regexp = new RegExp$1(pattern, "u");
    const predicate = (string) => regexp.test(string);
    if (name === "name") {
      return (entity, _parent) => predicate(entity.name);
    } else if (name === "qualified-name") {
      return (entity, parent) =>
        predicate(
          entity.type === "closure"
            ? `${parent.name}${entity.static ? "#" : "."}${entity.name}`
            : entity.name,
        );
    } else if (name === "some-label") {
      return (entity, _parent) => entity.labels.some(predicate);
    } else if (name === "every-label") {
      return (entity, _parent) => entity.labels.every(predicate);
    } /* c8 ignore start */ else {
      throw new InternalAppmapError("invalid clause name");
    } /* c8 ignore stop */
  } /* c8 ignore start */ else {
    throw new InternalAppmapError("invalid clause pattern type");
  } /* c8 ignore stop */
};

const compileClauseArray = (combinator, clauses) => {
  const predicates = toEntries$1(clauses).map(compileClause);
  if (combinator === "and") {
    return (node, naming) =>
      predicates.every((predicate) => predicate(node, naming));
  } else if (combinator === "or") {
    return (node, naming) =>
      predicates.some((predicate) => predicate(node, naming));
  } /* c8 ignore start */ else {
    throw new InternalAppmapError("invalid exclusion combinator");
  } /* c8 ignore stop */
};

const compileCriterion = ({ combinator, excluded, recursive, ...clauses }) => {
  const predicate = compileClauseArray(combinator, clauses);
  const spec = { excluded, recursive };
  return (node, naming) => (predicate(node, naming) ? spec : null);
};

const compileCriteria = (criteria) => {
  const closures = criteria.map(compileCriterion);
  return (node, naming) => {
    for (const closure of closures) {
      const maybe_spec = closure(node, naming);
      if (maybe_spec !== null) {
        return maybe_spec;
      }
    }
    throw new InternalAppmapError("missing matching exclusion criterion");
  };
};

const { Map: Map$8, String: String$a } = globalThis;

const getChild = (object, index) => object.children[index];

const hasFunctionType = ({ type }) => type === "function";

const printCommentArray = (comments) => {
  const { length } = comments;
  if (length === 0) {
    return null;
  } else {
    return comments.map(printComment).join("\n");
  }
};

////////////
// Create //
////////////

const registerClosure = (entity, path, closures) => {
  if (entity.type === "closure") {
    closures.set(stringifyPosition(entity.position), path);
  }
  const { length } = entity.children;
  for (let index = 0; index < length; index += 1) {
    registerClosure(
      entity.children[index],
      `${path}/${String$a(index)}`,
      closures,
    );
  }
};

const registerClosureRoot = (entity) => {
  assert(
    entity.type === "file",
    "root entity should be a file",
    InternalAppmapError,
  );
  const closures = new Map$8();
  const { length } = entity.children;
  for (let index = 0; index < length; index += 1) {
    registerClosure(entity.children[index], String$a(index), closures);
  }
  return closures;
};

const createSource$1 = ({ url, content, program }) => {
  const entity = toEntity(program, getUrlBasename(url));
  return {
    url,
    content,
    program,
    root: entity,
    closures: registerClosureRoot(entity),
  };
};

/////////////
// Exclude //
/////////////

const excludeEntityDeeply = (entity, excluded) => {
  entity.excluded = excluded;
  for (const child of entity.children) {
    excludeEntityDeeply(child, excluded);
  }
};

const excludeEntity = (entity, parent, exclude) => {
  const { excluded, recursive } = exclude(entity, parent);
  if (recursive) {
    excludeEntityDeeply(entity, excluded);
  } else {
    entity.excluded = excluded;
    for (const child of entity.children) {
      excludeEntity(child, entity, exclude);
    }
  }
};

const applyExclusionCriteria = ({ root }, criteria) => {
  excludeEntity(root, null, compileCriteria(criteria));
};

///////////
// Query //
///////////

const LINE_WEIGHT = 1024;
const COLUMN_WEIGHT = 1;
const THRESHOLD = 10 * LINE_WEIGHT;

const DISTANCE_OPTIONS = {
  line_weight: LINE_WEIGHT,
  column_weight: COLUMN_WEIGHT,
  threshold: THRESHOLD,
};

const resolveClosurePosition = ({ closures }, position) =>
  resolvePosition(closures, position, DISTANCE_OPTIONS);

const isClosurePositionExcluded = ({ closures, root }, position) => {
  const key = stringifyPosition(position);
  assert(closures.has(key), "missing closure", InternalAppmapError);
  return closures.get(key).split("/").reduce(getChild, root).excluded;
};

const lookupClosurePosition = (
  { root, closures, content },
  position,
) => {
  const key = stringifyPosition(position);
  assert(closures.has(key), "missing closure", InternalAppmapError);
  let parent = null;
  let entity = root;
  for (const index of closures.get(key).split("/")) {
    parent = entity;
    entity = entity.children[index];
  }
  entity.used = true;
  return {
    excluded: entity.excluded,
    parameters: entity.parameters.map(({ start, end }) =>
      content.substring(start, end),
    ),
    parent: parent.name,
    name: entity.name,
    static: entity.static,
    labels: entity.labels,
  };
};

////////////
// Digest //
////////////

const digestEntity = (entity, context) => {
  const children = entity.children.flatMap((child) =>
    digestEntity(child, context),
  );
  if (entity.excluded) {
    return children;
  } else {
    if (entity.type === "file") {
      if (children.some(hasFunctionType)) {
        return [
          {
            type: "class",
            name: entity.name,
            children,
          },
        ];
      } else {
        return children;
      }
    } else if (entity.type === "class") {
      if (children.length === 0 && context.pruning) {
        return [];
      } else {
        return [
          {
            type: "class",
            name: entity.name,
            children,
          },
        ];
      }
    } else if (entity.type === "closure") {
      return [
        ...(!entity.used && context.pruning
          ? []
          : [
              {
                type: "function",
                name: entity.name,
                static: entity.static,
                location: `${context.specifier}:${entity.position.line}`,
                source: context.inline
                  ? context.content.substring(
                      entity.boundary.start,
                      entity.boundary.end,
                    )
                  : null,
                comment: printCommentArray(entity.comments),
                labels: entity.labels,
              },
            ]),
        ...(children.length === 0
          ? []
          : [
              {
                type: "class",
                name: entity.name,
                children,
              },
            ]),
      ];
    } /* c8 ignore start */ else {
      throw new InternalAppmapError("invalid classmap entity type");
    } /* c8 ignore stop */
  }
};

const exportClassmap$1 = ({ root, content }, options) =>
  digestEntity(root, { content, ...options });

const setUrlHash = (url, hash) => {
  const url_obj = new URL$b(url);
  url_obj.hash = hash;
  return url_obj.toString();
};

const toSpecifier = (url, base) => {
  const relative = toRelativeUrl(url, base);
  if (relative === null) {
    return url;
  } else if (relative.startsWith("./") || relative.startsWith("../")) {
    return relative;
  } else {
    return `./${relative}`;
  }
};

const toDynamicSpecifier = (url, base, version) =>
  toSpecifier(setUrlHash(url, `#${version}`), base);

const toStaticSpecifier = (url, base) =>
  toSpecifier(setUrlHash(url, ""), base);

const splitSpecifier = (specifier) => {
  if (specifier.startsWith("./") || specifier.startsWith("../")) {
    return specifier.split("/");
  } else if (/^[a-zA-Z]+:\/\//u.test(specifier)) {
    const { protocol, host, pathname, search, hash } = new URL$b(specifier);
    assert(
      pathname.startsWith("/"),
      "url pathname should start with a slash",
      InternalAppmapError,
    );
    const dirnames = pathname.substring(1).split("/");
    const filename = `${dirnames.pop()}${search}${hash}`;
    return [`${protocol}//${host}`, ...dirnames, filename];
  } else {
    throw new InternalAppmapError("invalid specifier");
  }
};

const splitSpecifierDirectory = (specifier) => {
  const segments = splitSpecifier(specifier);
  segments.pop();
  if (segments[0] === "." && segments.length > 1) {
    segments.shift();
  }
  return segments;
};

const { Set: Set$3, Map: Map$7, String: String$9 } = globalThis;

/////////////
// factory //
/////////////

const registerFileUrl = (
  { url },
  codebase,
  disabled,
  {
    "inline-source": global_inline,
    exclude: global_criteria,
    packages: package_matcher_array,
    "default-package": default_package,
  },
) => {
  if (disabled.has(url)) {
    return false;
  } else if (codebase.has(url)) {
    return true;
  } else {
    const {
      enabled,
      exclude: criteria,
      "inline-source": inline,
      "source-type": source,
      parsing: plugins,
      shallow,
    } = lookupUrl(package_matcher_array, url, default_package);
    if (enabled) {
      codebase.set(url, {
        inline: inline === null ? global_inline : inline,
        criteria: [...criteria, ...global_criteria],
        shallow,
        parsing: { source, plugins },
        versions: new Map$7(),
      });
      return true;
    } else {
      disabled.add(url);
      return false;
    }
  }
};

const registerFile = ({ url, hash, content }, codebase) => {
  const { versions, criteria, parsing } = codebase.get(url);
  const version = String$9(versions.size);
  const source = createSource$1({
    url,
    content,
    program: parseEstree({ url, content }, parsing),
  });
  applyExclusionCriteria(source, criteria);
  versions.set(hash, { version, source });
};

const createCodebase$1 = (files, configuration) => {
  const codebase = new Map$7();
  const disabled = new Set$3();
  for (const file of files) {
    if (registerFileUrl(file, codebase, disabled, configuration)) {
      registerFile(file, codebase);
    }
  }
  const {
    repository: { directory: base },
    "collapse-package-hierachy": collapse,
    pruning,
  } = configuration;
  return {
    codebase,
    disabled,
    pruning,
    collapse,
    base,
  };
};

///////////
// query //
///////////

const completeClosure = (source, specifier, shallow, position) => {
  const maybe_resolved_position = resolveClosurePosition(source, position);
  if (maybe_resolved_position === null) {
    return null;
  } else {
    return {
      ...lookupClosurePosition(source, maybe_resolved_position),
      position: maybe_resolved_position,
      shallow,
      specifier,
    };
  }
};

const lookupClosureLocation = (
  { codebase, disabled, base },
  location,
) => {
  const { url, hash, position } = location;
  if (codebase.has(url)) {
    const { shallow, versions } = codebase.get(url);
    if (/* c8 ignore start */ versions.size === 0) {
      throw new InternalAppmapError("unexpected source without version");
    } /* c8 ignore stop */ else if (versions.size === 1) {
      const {
        value: { source },
      } = versions.values().next();
      return completeClosure(
        source,
        toStaticSpecifier(url, base),
        shallow,
        position,
      );
    } else {
      if (hash === null) {
        logWarning(
          "Ignoring closure at %j because its source has multiple versions",
          location,
        );
        return null;
      } else {
        if (versions.has(hash)) {
          const { source, version } = versions.get(hash);
          return completeClosure(
            source,
            toDynamicSpecifier(url, base, version),
            shallow,
            position,
          );
        } else {
          logWarning(
            "Ignoring closure at %j because of source content mismatch",
            location,
          );
          return null;
        }
      }
    }
  } else {
    logWarningWhen(
      !disabled.has(url),
      "Ignoring closure at %j because its source is missing",
      location,
    );
    return null;
  }
};

////////////
// export //
////////////

const registerPackage = (entities, segment) => {
  const predicate = (entity) =>
    entity.type === "package" && entity.name === segment;
  if (!entities.some(predicate)) {
    entities.push({ type: "package", name: segment, children: [] });
  }
  return entities.find(predicate).children;
};

const exportClassmap = ({ codebase, base, pruning, collapse }) => {
  const root = [];
  for (const [url, { inline, versions }] of codebase.entries()) {
    for (const { version, source } of versions.values()) {
      const specifier =
        versions.size === 1
          ? toStaticSpecifier(url, base)
          : toDynamicSpecifier(url, base, version);
      const children = exportClassmap$1(source, {
        specifier,
        inline,
        pruning,
      });
      if (
        /* c8 ignore start */ !pruning ||
        children.length > 0 /* c8 ignore stop */
      ) {
        if (collapse) {
          root.push({
            type: "package",
            name: specifier,
            children,
          });
        } else {
          splitSpecifierDirectory(specifier)
            .reduce(registerPackage, root)
            .push(...children);
        }
      }
    }
  }
  return root;
};

const { undefined: undefined$3 } = globalThis;

/* c8 ignore start */
const getName = ({ name }) => name;

const makeClient = (agent) => {
  if (agent === null) {
    agent = {
      directory: null,
      package: {
        name: "@appland/appmap-agent-js",
        version: "???",
        homepage: undefined$3,
      },
    };
  }
  const {
    package: { name, version, homepage },
  } = agent;
  return {
    name,
    version,
    url:
      homepage === null || homepage === undefined$3
        ? "https://github.com/applandinc/appmap-agent-js"
        : homepage,
  };
};

/* c8 ignore stop */

const makeJustRecording = ({
  "defined-class": defined_class,
  "method-id": method_id,
}) => ({
  defined_class,
  method_id,
});

const makeRecording = (recording) => mapMaybe(recording, makeJustRecording);

const sanitizeHistory = ({ repository, branch, commit, ...rest }) => ({
  repository: recoverMaybe(repository, "APPMAP-MISSING-REPOSITORY-NAME"),
  branch: recoverMaybe(branch, "APPMAP-MISSING-REPOSITORY-BRANCH"),
  commit: recoverMaybe(commit, "APPMAP-MISSING-REPOSITORY-COMMIT"),
  ...rest,
});

const makeGit = ({ history }) => mapMaybe(history, sanitizeHistory);

const makeAppName = (app_name, { package: _package }) =>
  app_name === null ? mapMaybe(_package, getName) : app_name;

const makeMapName = (map_name, file_name, main) => {
  if (map_name !== null) {
    return map_name;
  }
  if (file_name !== null) {
    return file_name;
  }
  if (main !== null) {
    return getUrlBasename(main);
  }
  return null;
};

const makeTestStatus = (termination) => {
  if (termination.type === "test") {
    return termination.passed ? "succeeded" : "failed";
  } else {
    return null;
  }
};

const makeRecorder = (recorder) => {
  assert(
    recorder !== null,
    "recorder should have been resolved earlier",
    InternalAppmapError,
  );
  return { name: recorder };
};

const makeException = (serials) => {
  if (serials.length === 0) {
    return null;
  } else {
    const serial = serials[0];
    if (serial.type === "object" || serial.type === "function") {
      if (serial.specific !== null && serial.specific.type === "error") {
        return {
          class: serial.specific.name,
          message: serial.specific.message,
        };
      } else {
        return {
          class: serial.constructor,
          message: serial.print,
        };
      }
    } else {
      return {
        class: serial.type,
        message: serial.print,
      };
    }
  }
};

/* c8 ignore start */
const compileMetadata = (
  {
    name: app_name,
    "map-name": map_name,
    repository,
    labels,
    frameworks,
    language,
    engine,
    agent,
    main,
    appmap_file: file_name,
    recorder,
    recording,
  },
  errors,
  termination,
) => ({
  name: makeMapName(map_name, file_name, main) ?? undefined$3,
  app: makeAppName(app_name, repository) ?? undefined$3,
  labels: labels ?? undefined$3,
  language: {
    name: language,
    version: "ES.Next",
    engine: engine ?? undefined$3,
  },
  frameworks: frameworks ?? undefined$3,
  client: makeClient(agent),
  recorder: makeRecorder(recorder),
  recording: makeRecording(recording) ?? undefined$3,
  git: makeGit(repository) ?? undefined$3,
  test_status: makeTestStatus(termination) ?? undefined$3,
  exception: makeException(errors) ?? undefined$3,
});
/* c8 ignore stop */

const {
  String: String$8,
  undefined: undefined$2,
  Object: { entries: toEntries },
  Array: { from: arrayFrom },
} = globalThis;

const parseURL = (url, headers) =>
  new URL$b(
    url[0] === "/"
      ? `http://${coalesceCaseInsensitive(headers, "host", "localhost")}${url}`
      : url,
  );

// const placeholder = {
//   link: {
//     defined_class: "MANUFACTURED_APPMAP_CLASS",
//     lineno: 0,
//     method_id: "MANUFACTURED_APPMAP_METHOD",
//     static: false,
//     path: "MANUFACTURED_APPMAP_FILE.js",
//   },
//   parameters: [],
// };

const isFirstColon = ([string]) => string.startsWith(":");

const digestSearchMessage = (search) =>
  arrayFrom(new URLSearchParams(search).entries());

// export for testing
const digestParameterPrimitive = (name, primitive) => ({
  name,
  class: typeof primitive,
  object_id: undefined$2,
  value: String$8(primitive),
});

const digestParameterPrimitiveTuple = ([name, primitive]) =>
  digestParameterPrimitive(name, primitive);

const digestSpecificHashEntry = ([key, value]) => ({
  name: key,
  class: value,
});

const digestSpecific = (specific) => {
  if (specific === null) {
    return null;
  } else if (specific.type === "array") {
    return { size: specific.length };
  } else if (specific.type === "hash") {
    return {
      size: specific.length,
      properties: toEntries(specific.properties).map(digestSpecificHashEntry),
    };
  } else {
    return null;
  }
};

// export for testing
const digestParameterSerial = (name, serial) => {
  if (serial.type === "object" || serial.type === "function") {
    return {
      name,
      class: serial.constructor,
      object_id: serial.index,
      value: serial.print,
      ...digestSpecific(serial.specific),
    };
  } else {
    return {
      name,
      class: serial.type,
      object_id: serial.type === "symbol" ? serial.index : undefined$2,
      value: serial.print,
    };
  }
};

const digestParameterSerialReturn = (serial) =>
  digestParameterSerial("return", serial);

const digestParameterSerialTuple = ([name, serial]) =>
  digestParameterSerial(name, serial);

const extractErrorSpecific = (specific) =>
  specific !== null && specific.type === "error"
    ? specific
    : { message: null, stack: null };

// export for testing
const digestExceptionSerial = (serial) => {
  if (serial.type === "object" || serial.type === "function") {
    const { message, stack } = extractErrorSpecific(serial.specific);
    return {
      class: serial.constructor,
      message: recoverMaybe(message, serial.print),
      object_id: serial.index,
      // TODO: extract path from stack
      path: stack ?? undefined$2,
      // TODO: extract line number from stack
      lineno: undefined$2,
    };
  } else {
    return {
      class: serial.type,
      message: serial.print,
      object_id: serial.type === "symbol" ? serial.index : 0,
      path: undefined$2,
      lineno: undefined$2,
    };
  }
};

const digesters = {
  // function //
  apply: ({ this: _this, arguments: _arguments }, { link, parameters }) => ({
    ...link,
    // TODO: It would make more sense to allow receiver to be null.
    // receiver: mapMaybe(this, digestParameterSerialThis),
    receiver:
      _this === null
        ? digestParameterPrimitive("this", undefined$2)
        : digestParameterSerial("this", _this),
    parameters: zip(parameters, _arguments).map(digestParameterSerialTuple),
  }),
  return: ({ result }, _options) => ({
    return_value: digestParameterSerial("return", result),
    exceptions: undefined$2,
  }),
  throw: ({ error }, _options) => ({
    return_value: undefined$2,
    exceptions: [digestExceptionSerial(error)],
  }),
  // http //
  request: ({ side, protocol, method, url, headers, route }, _options) => {
    const { origin, pathname, search } = parseURL(url, headers);
    if (side === "server") {
      return {
        http_server_request: {
          protocol,
          request_method: method,
          path_info: pathname,
          normalized_path_info: route,
          headers,
        },
        message: [
          ...(route === null
            ? []
            : zip(route.split("/"), pathname.split("/")).filter(isFirstColon)),
          ...digestSearchMessage(search),
        ].map(digestParameterPrimitiveTuple),
      };
    } else if (side === "client") {
      return {
        http_client_request: {
          request_method: method,
          url: `${origin}${pathname}`,
          headers,
        },
        message: digestSearchMessage(search).map(digestParameterPrimitiveTuple),
      };
    } /* c8 ignore start */ else {
      throw new InternalAppmapError("invalid request side");
    } /* c8 ignore stop */
  },
  response: ({ side, status, headers, body }, _options) => ({
    [`http_${side}_response`]: {
      status_code: status,
      headers,
      return_value: mapMaybe(body, digestParameterSerialReturn),
    },
  }),
  // sql //
  query: ({ database, version, sql, parameters }, _options) => ({
    sql_query: {
      database_type: database,
      server_version: version,
      sql,
      explain_sql: undefined$2,
    },
    message: toEntries(parameters).map(digestParameterSerialTuple),
  }),
  answer: ({}, _options) => ({}),
};

const digestPayload = (payload, options) => {
  const { type } = payload;
  assert(
    hasOwnProperty(digesters, type),
    "cannot digest payload",
    InternalAppmapError,
  );
  return digesters[type](payload, options);
};

const { Map: Map$6 } = globalThis;

const digestEventPair = (event1, event2, id1, id2, info) => [
  {
    event: "call",
    thread_id: 0,
    id: id1,
    ...digestPayload(event1.payload, info),
  },
  {
    event: "return",
    thread_id: 0,
    id: id2,
    parent_id: id1,
    elapsed: (event2.time - event1.time) / 1000,
    ...digestPayload(event2.payload, info),
  },
];

const toClosureInfo = ({
  excluded,
  specifier,
  position: { line },
  parent,
  name,
  static: is_static,
  parameters,
  shallow,
}) => ({
  excluded,
  link: {
    path: specifier,
    lineno: line,
    defined_class: parent,
    static: is_static,
    method_id: name,
  },
  shallow,
  parameters,
});

const digestEventTrace = (root, codebase) => {
  const counter = createCounter(0);
  const cache = new Map$6();
  const getClosureInfo = (location_string) => {
    if (cache.has(location_string)) {
      return cache.get(location_string);
    } else {
      const info = mapMaybe(
        lookupClosureLocation(codebase, parseLocation(location_string)),
        toClosureInfo,
      );
      cache.set(location_string, info);
      return info;
    }
  };
  /* eslint-disable no-use-before-define */
  const digestTransparentBundle = ({ children }, _info) =>
    children.flatMap(loop);
  /* eslint-enable no-use-before-define */
  const digestShallowBundle = ({ begin, end }, info) =>
    digestEventPair(
      begin,
      end,
      incrementCounter(counter),
      incrementCounter(counter),
      info,
    );
  /* eslint-disable no-use-before-define */
  const digestDeepBundle = ({ begin, children, end }, info) => {
    const id1 = incrementCounter(counter);
    const digest = children.flatMap(loop);
    const id2 = incrementCounter(counter);
    const [event1, event2] = digestEventPair(begin, end, id1, id2, info);
    digest.unshift(event1);
    digest.push(event2);
    return digest;
  };
  /* eslint-enable no-use-before-define */
  const loop = (node) => {
    if (node.type === "bundle") {
      const {
        begin: {
          payload: { type },
        },
      } = node;
      if (type === "bundle" || type === "group") {
        return digestTransparentBundle(node);
      } else if (type === "apply") {
        const info = mapMaybe(node.begin.payload.function, getClosureInfo);
        if (info === null || info.excluded) {
          return digestTransparentBundle(node);
        } else if (info.shallow) {
          return digestShallowBundle(node, info);
        } else {
          return digestDeepBundle(node, info);
        }
      } else {
        return digestDeepBundle(node, null);
      }
    } else if (node.type === "jump") {
      const { before, after } = node;
      const {
        payload: { type },
      } = before;
      if (type === "jump" || type === "await" || type === "yield") {
        return [];
      } else {
        return digestEventPair(
          before,
          after,
          incrementCounter(counter),
          incrementCounter(counter),
          null,
        );
      }
    } /* c8 ignore start */ else {
      throw new InternalAppmapError("invalid node type");
    } /* c8 ignore stop */
  };
  return root.flatMap(loop);
};

// Resolve groups.
// Each top-level tree is associated to a group.
// These trees are inserted into their corresponding group/ungroup event pair.
// NB: group/ungroup event pairs appear when asynchronous ressources are registered.

const {
  Array: { from: toArray$3 },
  Map: Map$5,
  String: String$7,
} = globalThis;

const takeMap = (map, key) => {
  const value = map.get(key);
  map.delete(key);
  return value;
};

const makeGroupKey = (session, group) => `${session}/${String$7(group)}`;

const groupStack = (root) => {
  const deep_group_map = new Map$5();
  const root_group_map = new Map$5();
  for (const node of root) {
    const key = makeGroupKey(node.enter.session, node.enter.group);
    if (root_group_map.has(key)) {
      root_group_map.get(key).push(node);
    } else {
      root_group_map.set(key, [node]);
    }
  }
  const mapping = ({ enter, children, leave }) => {
    children = children.map(mapping);
    if (enter.site === "begin" && enter.payload.type === "group") {
      // NB: We want to use `enter.payload.group` and not `enter.group`.
      // - `enter.payload.group` is the id of the newly created async group.
      // - `enter.group` is the id of the current async group.
      const key = makeGroupKey(enter.session, enter.payload.group);
      if (root_group_map.has(key)) {
        for (const async_child of takeMap(root_group_map, key)) {
          children.push(mapping(async_child));
        }
      } else if (deep_group_map.has(key)) {
        for (const async_child of takeMap(deep_group_map, key)) {
          children.push(async_child);
        }
      }
    }
    return { enter, children, leave };
  };
  for (const key of root_group_map.keys()) {
    deep_group_map.set(key, takeMap(root_group_map, key).map(mapping));
  }
  return toArray$3(deep_group_map.values()).flat(1);
};

// Rearrenge the event trace into an array of trees.

const createJumpEvent = (session, site, tab, group, time) => ({
  type: "event",
  session,
  site,
  tab,
  group,
  time,
  payload: {
    type: "jump",
  },
});

const createFreshCounter = (events) => {
  let max = 0;
  for (const event of events) {
    if (event.tab > max) {
      max = event.tab;
    }
  }
  return createCounter(max);
};

const stackify = (events) => {
  const stack = [
    {
      enter: null,
      children: [],
      leave: null,
    },
  ];
  const counter = createFreshCounter(events);
  for (const event of events) {
    if (event.site === "begin" || event.site === "after") {
      stack.push({
        enter: event,
        children: [],
        leave: null,
      });
    } else if (event.site === "end" || event.site === "before") {
      let maybe_frame = null;
      for (
        let index = stack.length - 1;
        index >= 1 && maybe_frame === null;
        index -= 1
      ) {
        const frame = stack[index];
        if (frame.enter.session === event.session) {
          maybe_frame = stack[index];
        }
      }
      if (maybe_frame === null) {
        stack[0].children = [
          {
            enter: createJumpEvent(
              event.session,
              "after",
              incrementCounter(counter),
              event.group,
              event.time,
            ),
            children: stack[0].children,
            leave: event,
          },
        ];
      } else {
        assert(
          maybe_frame.leave === null,
          "frame has already been completed",
          InternalAppmapError,
        );
        maybe_frame.leave = event;
        while (stack.length > 1 && stack[stack.length - 1].leave !== null) {
          const frame = stack.pop();
          stack[stack.length - 1].children.push(frame);
        }
      }
    } /* c8 ignore start */ else {
      throw new InternalAppmapError("invalid event site");
    } /* c8 ignore stop */
  }
  while (stack.length > 1) {
    const frame = stack.pop();
    frame.leave = createJumpEvent(
      frame.enter.session,
      "before",
      incrementCounter(counter),
      frame.enter.group,
      frame.enter.time,
    );
    stack[stack.length - 1].children.push(frame);
  }
  return stack[0].children;
};

const payloads = {
  jump: {
    type: "jump",
  },
  bundle: {
    type: "bundle",
  },
  apply: {
    type: "apply",
    function: null,
    this: {
      type: "string",
      print: "APPMAP-APPLY",
    },
    arguments: [],
  },
  return: {
    type: "return",
    function: null,
    result: {
      type: "string",
      print: "APPMAP-RETURN",
    },
  },
  throw: {
    type: "throw",
    function: null,
    error: {
      type: "string",
      print: "APPMAP-THROW",
    },
  },
  request: {
    side: null,
    type: "request",
    protocol: "HTTP/1.1",
    method: "GET",
    path: "/APPMAP/REQUEST",
    route: null,
    headers: {},
    body: null,
  },
  response: {
    side: null,
    type: "response",
    status: 200,
    message: "APPMAP-RESPONSE",
    route: null,
    headers: {},
    body: null,
  },
  query: {
    type: "query",
    database: "",
    version: null,
    sql: "SELECT * FROM APPMAP-QUERY;",
  },
  answer: {
    type: "answer",
    error: null,
  },
  yield: {
    type: "yield",
    function: null,
    delegate: false,
    iterator: {
      type: "string",
      print: "APPMAP-YIELD",
    },
  },
  await: {
    type: "await",
    function: null,
    promise: {
      type: "string",
      print: "APPMAP-AWAIT",
    },
  },
  resolve: {
    type: "resolve",
    function: null,
    result: {
      type: "APPMAP-RESOLVE",
    },
  },
  reject: {
    type: "reject",
    function: null,
    error: {
      type: "APPMAP-REJECT",
    },
  },
  group: {
    type: "group",
    group: null,
    description: "MISSING",
  },
  ungroup: {
    type: "ungroup",
    group: null,
  },
};

const matching = [
  ["begin/bundle", "end/bundle", []],
  ["begin/apply", "end/return", ["function"]],
  ["begin/apply", "end/throw", ["function"]],
  ["begin/request", "end/response", ["side"]],
  ["begin/group", "end/ungroup", ["group"]],
  ["before/await", "after/resolve", ["function"]],
  ["before/await", "after/reject", ["function"]],
  ["before/yield", "after/resolve", ["function"]],
  ["before/yield", "after/reject", ["function"]],
  ["before/jump", "after/jump", []],
  ["before/request", "after/response", ["side"]],
  ["before/query", "after/answer", []],
];

const makeMatchingKey = ({ site, payload: { type } }) => `${site}/${type}`;

const makeMatch = (key, copying) => {
  const [site, type] = key.split("/");
  return { site, type, copying };
};

const lookupMatch = (event) => {
  const key = makeMatchingKey(event);
  for (const match of matching) {
    if (match[0] === key) {
      return makeMatch(match[1], match[2]);
    } else if (match[1] === key) {
      return makeMatch(match[0], match[2]);
    }
  }
  throw new InternalAppmapError(
    "invalid combination of event site and event payload type",
  );
};

const manufactureMatchingEvent = (event) => {
  const { site, type, copying } = lookupMatch(event);
  const payload = { ...payloads[type] };
  for (const field of copying) {
    payload[field] = event.payload[field];
  }
  return {
    type: "event",
    session: event.session,
    site,
    tab: event.tab,
    time: event.time,
    group: event.group,
    payload,
  };
};

const isMatchingEvent = (event1, event2) => {
  const key1 = makeMatchingKey(event1);
  const key2 = makeMatchingKey(event2);
  for (const match of matching) {
    if (match[0] === key1 && match[1] === key2) {
      for (const field of match[2]) {
        if (event1.payload[field] !== event2.payload[field]) {
          return false;
        }
      }
      return event1.session === event2.session && event1.tab === event2.tab;
    }
  }
  return false;
};

// Resolve jumps.

const {
  Array: { from: toArray$2 },
  Map: Map$4,
  String: String$6,
} = globalThis;

const makeJumpKey = ({ session, tab }) => `${session}/${String$6(tab)}`;

const manufactureBundleEvent = (session, site, tab) => ({
  type: "event",
  session,
  site,
  tab,
  group: 0,
  time: 0,
  payload: {
    type: "bundle",
  },
});

const makeBundleNode = (begin, children, end) => {
  assert(
    isMatchingEvent(begin, end),
    "begin/end event mismatch",
    InternalAppmapError,
  );
  return {
    type: "bundle",
    begin,
    children,
    end,
  };
};

const makeJumpNode = (before, after) => {
  assert(
    isMatchingEvent(before, after),
    "before/after event mismatch",
    InternalAppmapError,
  );
  return {
    type: "jump",
    before,
    after,
  };
};

const makeOrphan = (open, children, close) => ({
  open,
  children,
  close,
});

const manufactureBundleNode = (orphan) => {
  if (orphan.open.site === "begin" && orphan.close.site === "end") {
    return makeBundleNode(orphan.open, orphan.children, orphan.close);
  } else if (orphan.open.site === "after" && orphan.close.site === "before") {
    return makeBundleNode(
      manufactureBundleEvent(orphan.open.session, "begin", 0),
      [
        makeJumpNode(manufactureMatchingEvent(orphan.open), orphan.open),
        ...orphan.children,
        makeJumpNode(orphan.close, manufactureMatchingEvent(orphan.close)),
      ],
      manufactureBundleEvent(orphan.close.session, "end", 0),
    );
  } else if (orphan.open.site === "after" && orphan.close.site === "end") {
    return makeBundleNode(
      manufactureMatchingEvent(orphan.close),
      [
        makeJumpNode(manufactureMatchingEvent(orphan.open), orphan.open),
        ...orphan.children,
      ],
      orphan.close,
    );
  } else if (orphan.open.site === "begin" && orphan.close.site === "before") {
    return makeBundleNode(
      orphan.open,
      [
        ...orphan.children,
        makeJumpNode(orphan.close, manufactureMatchingEvent(orphan.close)),
      ],
      manufactureMatchingEvent(orphan.open),
    );
  } /* c8 ignore start */ else {
    throw new InternalAppmapError("invalid enter/leave event site");
  } /* c8 ignore stop */
};

const splitJump = (frames, jumps) => {
  const filtering = (frame) => {
    if (frame.enter.site === "after") {
      const key = makeJumpKey(frame.enter);
      assert(!jumps.has(key), "duplicate jump", InternalAppmapError);
      jumps.set(key, frame);
      return false;
    } else {
      return true;
    }
  };
  const mapping = ({ enter, children, leave }) => ({
    enter,
    children: children.map(mapping).filter(filtering),
    leave,
  });
  return frames.map(mapping).filter(filtering);
};

const joinJump = (frames, jumps) => {
  /* eslint-disable no-use-before-define */
  const mapBeginFrame = (frame) => manufactureBundleNode(mapFrame(frame));
  /* eslint-enable no-use-before-define */
  const orphans = new Map$4();
  const mapFrame = (frame) => {
    const open = frame.enter;
    const nodes = frame.children.map(mapBeginFrame);
    let close = frame.leave;
    while (close.site === "before") {
      const key = makeJumpKey(close);
      if (jumps.has(key)) {
        const frame = jumps.get(key);
        jumps.delete(key);
        nodes.push(makeJumpNode(close, frame.enter));
        nodes.push(...frame.children.map(mapBeginFrame));
        close = frame.leave;
      } else if (orphans.has(key)) {
        const orphan = orphans.get(key);
        orphans.delete(key);
        nodes.push(makeJumpNode(close, orphan.open));
        nodes.push(...orphan.children);
        close = orphan.close;
      } else {
        return makeOrphan(open, nodes, close);
      }
    }
    return makeOrphan(open, nodes, close);
  };
  const nodes = frames.map(mapBeginFrame);
  for (const key of jumps.keys()) {
    const frame = jumps.get(key);
    jumps.delete(key);
    orphans.set(key, mapFrame(frame));
  }
  return [].concat(toArray$2(orphans.values()).map(manufactureBundleNode), nodes);
};

const jumpify = (root) => {
  const jumps = new Map$4();
  return joinJump(splitJump(root, jumps), jumps);
};

// Beware, event ordering is by far the most difficult code to understand.

const orderEventArray = (events) =>
  jumpify(groupStack(stackify(events)));

const { encodeURIComponent } = globalThis;

const pickBasename = ({ appmap_file: basename, "map-name": name }) => {
  if (basename !== null) {
    return basename;
  } else if (name !== null) {
    return name;
  } else {
    return "anonymous";
  }
};

const getOutputUrl = (configuration) =>
  toAbsoluteUrl(
    `${configuration.recorder}/${encodeURIComponent(
      sanitizePathFilename(`${pickBasename(configuration)}.appmap.json`),
    )}`,
    configuration.appmap_dir,
  );

const {
  Map: Map$3,
  Array: { from: toArray$1 },
  String: String$5,
  Math: { round },
  RangeError,
} = globalThis;

const VERSION = "1.8.0";

const TOTAL_EVENT_THRESHOLD = 1e6;

const GROUP_EVENT_THRESHOLD = 5e5;

const APPLY_EVENT_THRESHOLD = 1e5;

const STACKOVERFLOW_MESSAGE = `\
We could not process your appmap because it has too many events (that are deeply nested). \
The preferred method to solve this issue is to reduce the size of the appmap. \
Alternatively, you could try to increase the callstack size of this node process:
\`\`\`
> node --stack-size=5000 node_modules/bin/appmap-agent-js -- npm run test
\`\`\`
NB: Unfortunately, \`--stack-size'\` cannot be set via the \`NODE_OPTIONS\` environment variable.\
`;

const TOO_MANY_GROUP_EVENT_MESSAGE = `\
Many recorded events were related to tracking asynchronous resources. \
This impacts the performance of the javascript agent and may cause memory issues. \
It is possible to no longer record them by adding \`ordering: chronological\` to the appmap.yml file. \
This would speed up the execution of the agent but would make it unable to track the origin of callbacks. \
Note that async/await structure will still be preserved.\
`;

const TOO_MANY_APPLY_EVENT_MESSAGE = `\
Many function applications were recorded. \
The appmap framework works best with smaller appmaps. \
Beside reducing the scope of the recording (eg: smaller test cases or shorter remote recording) the configuration file can be tweaked to exclude functions from recording. \
Let's say we recorded this function many times:
  \`\`\`js
  /* util.js */
  // @label appmap-exclude
  export const isNull = (any) => any === null;
  \`\`\`
  There are many ways to exclude it:
  \`\`\`yaml
  # appmap.yml #
  # global function exclusion #
  exclude:
    - name: isNull
    - qualified-name: util.isNull
    - some-label: appmap-exclude
  packages:
    # file-scoped function exclusion #
    - glob: util.js
      exclude:
        - name: isNull
    # file exclusion #
    - glob: util.js
      enabled: false
  \`\`\`
`;

const countApplyEvent = (count, { payload: { type } }) =>
  type === "apply" ? count + 1 : count;

const countGroupEvent = (count, { payload: { type } }) =>
  type === "group" ? count + 1 : count;

const printLocation = ({ url, position: { line, column } }) =>
  `${url}:${String$5(line)}:${String$5(column)}`;

const printCount = (count, total) =>
  `${String$5(count)} [${String$5(round((100 * count) / total))}%]`;

const chartEvent = (events) => {
  const counters = new Map$3();
  for (const { payload } of events) {
    const { type } = payload;
    counters.set(type, (counters.has(type) ? counters.get(type) : 0) + 1);
  }
  return counters;
};

const printEventCount = (name, count, total) =>
  `  - ${name}: ${printCount(count, total)}\n`;

const printEventDistribution = (events) => {
  const counters = chartEvent(events);
  const { length: total } = events;
  return toArray$1(counters.keys())
    .sort((key1, key2) => counters.get(key2) - counters.get(key1))
    .map((key) => printEventCount(key, counters.get(key), total))
    .join("");
};

const chartApplyEvent = (events) => {
  const counters = new Map$3();
  for (const { payload } of events) {
    if (payload.type === "apply") {
      const { function: location } = payload;
      counters.set(
        location,
        (counters.has(location) ? counters.get(location) : 0) + 1,
      );
    }
  }
  return counters;
};

const printApplyEventCount = (location, count, total, codebase) => {
  const maybe = lookupClosureLocation(codebase, location);
  const lines = [];
  lines.push(`  - ${printLocation(location)} >> ${printCount(count, total)}`);
  /* c8 ignore start */
  if (maybe === null) {
    lines.push(
      "    We could not find any information associated to this function...",
    );
  } else {
    const { excluded } = maybe;
    if (excluded) {
      lines.push(
        "    This function was excluded but postmortem so it was still recorded.",
        "    To no longer record this function use: `postmortem-function-exclusion: false`.",
      );
    } else {
      const { labels, name, parent, static: static_ } = maybe;
      lines.push(
        "    This function can be excluded with the following criteria:",
        `      - name: ${name}`,
        `      - qualified-name: ${parent}${static_ ? "#" : "."}${name}`,
      );
      if (labels.length > 0) {
        lines.push(`      - labels: ${labels.join(", ")}`);
      }
    }
    lines.push("");
  }
  /* c8 ignore stop */
  return lines.join("\n");
};

const printApplyEventDistribution = (events, codebase) => {
  const counters = chartApplyEvent(events);
  const total = events.reduce(countApplyEvent, 0);
  return toArray$1(counters.keys())
    .sort((key1, key2) => counters.get(key2) - counters.get(key1))
    .slice(0, 7)
    .map((key) =>
      printApplyEventCount(
        parseLocation(key),
        counters.get(key),
        total,
        codebase,
      ),
    )
    .join("");
};

const compileTrace = (configuration, files, messages, termination) => {
  logDebug("Trace: %j", { configuration, files, messages, termination });
  const errors = [];
  const events = [];
  for (const message of messages) {
    const { type } = message;
    if (type === "error") {
      errors.push(message.error);
    } else if (type === "event") {
      events.push(message);
    } else if (type === "group") {
      events.push(
        {
          type: "event",
          session: message.session,
          site: "begin",
          tab: 0,
          group: message.group,
          time: 0,
          payload: {
            type: "group",
            group: message.child,
            description: message.description,
          },
        },
        {
          type: "event",
          session: message.session,
          site: "end",
          tab: 0,
          group: message.group,
          time: 0,
          payload: {
            type: "ungroup",
            group: message.child,
          },
        },
      );
    } else if (type === "amend") {
      for (let index = events.length - 1; index >= 0; index -= 1) {
        const event = events[index];
        if (
          event.session === message.session &&
          event.tab === message.tab &&
          event.site === message.site
        ) {
          events[index] = { ...event, payload: message.payload };
          break;
        }
      }
    } /* c8 ignore start */ else {
      throw new InternalAppmapError("invalid core message type");
    } /* c8 ignore stop */
  }
  const url = getOutputUrl(configuration);
  const codebase = createCodebase$1(files, configuration);
  const total_count = events.length;
  const apply_count = events.reduce(countApplyEvent, 0);
  const group_count = events.reduce(countGroupEvent, 0);
  logInfo("AppMap %s", url);
  logInfoWhen(
    total_count > TOTAL_EVENT_THRESHOLD,
    "This appmap is very large (%j events), we will try our best to process it...",
    total_count,
  );
  logInfoWhen(
    total_count > TOTAL_EVENT_THRESHOLD,
    "Event distribution:\n%f",
    () => printEventDistribution(events),
  );
  logDebugWhen(
    total_count <= TOTAL_EVENT_THRESHOLD,
    "Event distribution:\n%f",
    () => printEventDistribution(events),
  );
  logInfoWhen(
    group_count > GROUP_EVENT_THRESHOLD,
    TOO_MANY_GROUP_EVENT_MESSAGE,
  );
  logInfoWhen(
    apply_count > APPLY_EVENT_THRESHOLD,
    TOO_MANY_APPLY_EVENT_MESSAGE,
  );
  logInfoWhen(
    apply_count > APPLY_EVENT_THRESHOLD,
    "Most frequently applied functions:\n%f",
    () => printApplyEventDistribution(events, codebase),
  );
  logDebugWhen(
    apply_count <= APPLY_EVENT_THRESHOLD,
    "Most frequently applied functions:\n%f",
    () => printApplyEventDistribution(events, codebase),
  );
  let digested_events = null;
  /* c8 ignore start */
  try {
    digested_events = digestEventTrace(orderEventArray(events), codebase);
  } catch (error) {
    if (error instanceof RangeError) {
      logError("Stack overflow error >> %O", error);
      logError(STACKOVERFLOW_MESSAGE);
      throw new ExternalAppmapError(
        "Stack overflow error during appmap processing",
      );
    } else {
      throw error;
    }
  }
  /* c8 ignore stop */
  const appmap = {
    version: VERSION,
    metadata: compileMetadata(configuration, errors, termination),
    classMap: exportClassmap(codebase),
    events: digested_events,
  };
  if (configuration.validate.appmap) {
    validateAppmap(appmap);
  }
  return {
    url: getOutputUrl(configuration),
    content: appmap,
  };
};

const { RegExp, Set: Set$2 } = globalThis;

const startTrack = (configuration) => ({
  configuration,
  regexp: new RegExp(configuration.sessions, "u"),
  sources: [],
  messages: [],
  termination: null,
  present: new Set$2(),
  missing: new Set$2(),
});

const stopTrack = (track, termination) => {
  track.termination = termination;
};

const compileTrack = (track) =>
  compileTrace(
    track.configuration,
    track.sources,
    track.messages,
    track.termination ?? { type: "unknown" },
  );

const makeStaticKey = ({ url }) => `|${url}`;

const makeDynamicKey = ({ url, hash }) => `${hash}|${url}`;

const addTrackSource = (track, source) => {
  track.sources.push(source);
  const key1 = makeStaticKey(source);
  track.present.add(key1);
  track.missing.delete(key1);
  if (source.hash !== null) {
    const key2 = makeDynamicKey(source);
    track.present.add(key2);
    track.missing.delete(key2);
  }
};

const sendTrack = (track, message) => {
  const { type, session } = message;
  if (track.regexp.test(session)) {
    if (type === "amend" || track.termination === null) {
      track.messages.push(message);
    }
    if (type === "event") {
      const { payload } = message;
      const { type: payload_type } = payload;
      if (
        payload_type === "apply" ||
        payload_type === "return" ||
        payload_type === "throw"
      ) {
        const location = parseLocation(payload.function);
        const key1 = makeStaticKey(location);
        if (!track.present.has(key1)) {
          track.missing.add(key1);
        }
        if (location.hash !== null) {
          const key2 = makeDynamicKey(location);
          if (!track.present.has(key2)) {
            track.missing.add(key2);
          }
        }
      }
    }
  }
};

const isTrackComplete = (track) =>
  track.termination !== null && track.missing.size === 0;

const {
  Map: Map$2,
  Boolean,
  Array: { from: toArray },
} = globalThis;

const processStartMessage = ({ tracks, sources }, key, configuration) => {
  if (tracks.has(key)) {
    logError("Duplicate track %j", key);
    return false;
  } else {
    const track = startTrack(configuration);
    for (const source of sources) {
      addTrackSource(track, source);
    }
    tracks.set(key, track);
    return true;
  }
};

// We do no compile the track at this points because additional
// source messages may still arrive. That is because the tranformer
// may reside on a different process.
const processStopMessage = ({ tracks }, key, termination) => {
  if (tracks.has(key)) {
    const track = tracks.get(key);
    stopTrack(track, termination);
    return true;
  } else {
    logError("missing track %j", key);
    return false;
  }
};

const createBackend = (configuration) => ({
  configuration,
  sources: [],
  tracks: new Map$2(),
});

const hasBackendTrack = ({ tracks }, key) => tracks.has(key);

const compileBackendTrack = ({ tracks }, key, abrupt) => {
  if (tracks.has(key)) {
    const track = tracks.get(key);
    if (abrupt || isTrackComplete(track)) {
      tracks.delete(key);
      return compileTrack(track);
    } else {
      return null;
    }
  } else {
    return null;
  }
};

const countBackendCompleteTrack = ({ tracks }) =>
  toArray(tracks.values()).map(isTrackComplete).filter(Boolean).length;

const compileBackendAvailableTrack = ({ tracks }, abrupt) => {
  for (const [key, track] of tracks) {
    if (abrupt || isTrackComplete(track)) {
      tracks.delete(key);
      return compileTrack(track);
    }
  }
  return null;
};

const isBackendEmpty = ({ tracks }) => tracks.size === 0;

const sendBackend = (backend, message) => {
  logDebug("message >> %j", message);
  if (backend.configuration.validate.message) {
    validateMessage(message);
  }
  const { type } = message;
  if (type === "start") {
    return processStartMessage(backend, message.track, message.configuration);
  } else if (type === "stop") {
    const { track: key } = message;
    if (key === null) {
      return toArray(backend.tracks.keys())
        .map((key) => processStopMessage(backend, key, message.termination))
        .every(identity);
    } else {
      return processStopMessage(backend, key, message.termination);
    }
  } else if (type === "source") {
    if (message.content === null) {
      logWarning("Ignoring file %j because it was empty", message.url);
    } else {
      const source = {
        url: message.url,
        content: message.content,
        hash: digest(message.content),
      };
      backend.sources.push(source);
      for (const track of backend.tracks.values()) {
        addTrackSource(track, source);
      }
    }
    return true;
  } else {
    for (const track of backend.tracks.values()) {
      sendTrack(track, message);
    }
    return true;
  }
};

const {
  setInterval,
  clearInterval,
  String: String$4,
  Set: Set$1,
  URL: URL$2,
  JSON: { parse: parseJSON$3 },
} = globalThis;

const BACK_PRESSURE_INTERVAL = 1000;

const { patch: patchSocket } = NetSocketMessaging;

const readFileSafe$1 = (url) => {
  try {
    return readFileSync(new URL$2(url), "utf8");
  } catch (error) {
    logWarning("Could not load source at %j >> %O", url, error);
    return null;
  }
};

const sendBackendAssert = (backend, message) => {
  assert(sendBackend(backend, message), "backend error", InternalAppmapError);
};

const createTraceServer = (backend) => {
  const server = createServer();
  server.on("connection", (socket) => {
    patchSocket(socket);
    socket.send(String$4(countBackendCompleteTrack(backend)));
    /* c8 ignore start */
    const timer = setInterval(() => {
      if (socket.writable) {
        socket.send(String$4(countBackendCompleteTrack(backend)));
      }
    }, BACK_PRESSURE_INTERVAL);
    timer.unref();
    /* c8 ignore stop */
    const tracks = new Set$1();
    /* c8 ignore start */
    socket.on("error", (error) => {
      logWarning("Socket error: %O", error);
    });
    /* c8 ignore stop */
    socket.on("close", () => {
      clearInterval(timer);
      // Normally hook-exit send a stop-all message.
      // But this message may never arrive due to
      // underlying network/buffer issue.
      // This serves as fallback mechanism.
      for (const track of tracks) {
        sendBackendAssert(backend, {
          type: "stop",
          track,
          termination: {
            type: "disconnect",
          },
        });
      }
      tracks.clear();
    });
    socket.on("message", (content) => {
      for (const message of inflate(parseJSON$3(content))) {
        if (message.type === "start") {
          tracks.add(message.track);
          sendBackendAssert(backend, message);
        } else if (message.type === "stop") {
          if (message.track === null) {
            for (const track of tracks) {
              sendBackendAssert(backend, {
                type: "stop",
                track,
                termination: message.termination,
              });
            }
            tracks.clear();
          } else {
            tracks.delete(message.track);
            sendBackendAssert(backend, message);
          }
        } else if (message.type === "source" && message.content === null) {
          sendBackendAssert(backend, {
            ...message,
            content: readFileSafe$1(message.url),
          });
        } else {
          sendBackendAssert(backend, message);
        }
      }
    });
  });
  return server;
};

const {
  Buffer: { from: toBuffer$3, concat: concatBuffer$1 },
  Promise: Promise$5,
  Error: Error$4,
  JSON: { parse: parseJSON$2, stringify: stringifyJSON$3 },
} = globalThis;

const INVALID_HEADERS_MESSAGE =
  "in the presence of a body, 'content-type' should be 'application/json; charset=UTF-8'";

const parse = (body) => {
  if (body === "") {
    return null;
  }
  return parseJSON$2(body);
};

const stringify = (data) => {
  if (data === null) {
    return "";
  }
  return stringifyJSON$3(data);
};

const areValidHeaders = (headers) =>
  !hasOwnProperty(headers, "content-length") ||
  headers["content-length"] === "0" ||
  (hasOwnProperty(headers, "content-type") &&
    headers["content-type"] === "application/json; charset=UTF-8");

const empty_headers = {
  "content-length": 0,
};

const createHeaders = ({ length }) => {
  if (length === 0) {
    return empty_headers;
  }
  return {
    "content-type": "application/json; charset=UTF-8",
    "content-length": length,
  };
};

const generateRespond = (respondAsync) => (request, response) => {
  if (areValidHeaders(request.headers)) {
    const buffers = [];
    request.on("data", (buffer) => {
      buffers.push(buffer);
    });
    request.on("end", async () => {
      const { code, message, body } = await respondAsync(
        request.method,
        request.url,
        parse(concatBuffer$1(buffers).toString("utf8")),
      );
      const buffer = toBuffer$3(stringify(body), "utf8");
      response.writeHead(code, message, createHeaders(buffer));
      response.end(buffer);
    });
  } else {
    request.on("data", noop);
    request.on("end", noop);
    response.writeHead(400, INVALID_HEADERS_MESSAGE, empty_headers);
    response.end();
  }
};

const success = {
  code: 200,
  message: "OK",
  body: null,
};

const failure = {
  code: 400,
  message: "Bad Request",
  body: null,
};

const createTrackServer = (configuration, backend) => {
  configuration = {
    ...configuration,
    recorder: "remote",
  };
  const server = createServer$1();
  server.on(
    "request",
    generateRespond((method, path, body) => {
      logDebug("Received remote recording request: %s %s", method, path);
      const parts = path.split("/");
      if (parts.length !== 3 || parts[0] !== "") {
        logError("Could not parse request path %j", path);
        return failure;
      } else {
        // Session is currently not used but it will be in the future.
        const [, , record] = parts;
        if (method === "POST") {
          if (
            sendBackend(backend, {
              type: "start",
              track: record,
              configuration: extendConfiguration(
                configuration,
                coalesce(body, "data", {}),
                coalesce(body, "path", null),
              ),
            })
          ) {
            return success;
          } else {
            return failure;
          }
        } else if (method === "GET") {
          return {
            ...success,
            body: { enabled: hasBackendTrack(backend, record) },
          };
        } else if (method === "DELETE") {
          if (
            sendBackend(backend, {
              type: "stop",
              track: record,
              termination: { type: "manual" },
            })
          ) {
            const maybe_trace = compileBackendTrack(backend, record, true);
            assert(
              maybe_trace !== null,
              "expected compiled trace after stop",
              InternalAppmapError,
            );
            return {
              ...success,
              body: maybe_trace.content,
            };
          } else {
            return failure;
          }
        } else {
          logError("Unsupported http method %j", method);
          return failure;
        }
      }
    }),
  );
  return server;
};

const { Promise: Promise$4 } = globalThis;

/* c8 ignore start */
const partialx_$1 = (f, x1) => (x2) => {
  f(x1, x2);
};
/* c8 ignore stop */

const openReceptorAsync = async (configuration, backend) => {
  const pool = createPool();
  const trace_server = createTraceServer(backend);
  const track_server = createTrackServer(configuration, backend);
  trace_server.on("connection", partialx_$1(addPool, pool));
  track_server.on("connection", partialx_$1(addPool, pool));
  trace_server.listen(convertPort(configuration["trace-port"]));
  track_server.listen(convertPort(configuration["track-port"]));
  await Promise$4.all([
    new Promise$4((resolve, reject) => {
      trace_server.on("error", reject);
      trace_server.on("listening", resolve);
    }),
    new Promise$4((resolve, reject) => {
      track_server.on("error", reject);
      track_server.on("listening", resolve);
    }),
  ]);
  logDebug("Trace port: %j", revertPort(trace_server.address()));
  logDebug("Track port: %j", revertPort(track_server.address()));
  return { trace_server, track_server, pool };
};

const getReceptorTracePort = ({ trace_server }) =>
  revertPort(trace_server.address());

const getReceptorTrackPort = ({ track_server }) =>
  revertPort(track_server.address());

const closeReceptorAsync = async ({
  trace_server,
  track_server,
  pool,
}) => {
  trace_server.close();
  track_server.close();
  closePool(pool, 1000);
  await Promise$4.all([
    new Promise$4((resolve, reject) => {
      trace_server.on("error", reject);
      trace_server.on("close", resolve);
    }),
    new Promise$4((resolve, reject) => {
      track_server.on("error", reject);
      track_server.on("close", resolve);
    }),
  ]);
};

const { setTimeout: setTimeout$1, Promise: Promise$3, undefined: undefined$1, Error: Error$3 } = globalThis;

const { concat: concatBuffer } = Buffer;

const compileSig = (signal) => (child) => {
  child.kill(signal);
};

const sigint = compileSig("SIGINT");

const sigkill = compileSig("SIGKILL");

const killAllAsync = (children) =>
  new Promise$3((resolve, reject) => {
    children.forEach(sigint);
    setTimeout$1(() => {
      children.forEach(sigkill);
      setTimeout$1(() => {
        /* c8 ignore start */ if (children.size !== 0) {
          reject(new Error$3("Could not kill all spawn child processes in time"));
        } /* c8 ignore stop */ else {
          resolve(undefined$1);
        }
      }, 1000);
    }, 1000);
  });

const bufferReadable$1 = (readable) => {
  const buffers = [];
  readable.on("data", (buffer) => {
    buffers.push(buffer);
  });
  return buffers;
};

const spawnAsync$1 = ({ exec, argv, options }, children) =>
  new Promise$3((resolve, reject) => {
    logDebug("Spawn %j %j %j", exec, argv, options);
    const child = spawn$1(exec, argv, {
      ...options,
      cwd:
        "cwd" in options
          ? fileURLToPath(toAbsoluteUrl(".", options.cwd))
          : cwd(),
    });
    const stdout =
      options.stdio === "pipe" ? bufferReadable$1(child.stdout) : null;
    const stderr =
      options.stdio === "pipe" ? bufferReadable$1(child.stderr) : null;
    child.on("error", (error) => {
      logDebug("Spawn failure %j %j >> %O", exec, argv, error);
      children.delete(child);
      reject(error);
    });
    child.on("close", (status, signal) => {
      logDebug(
        "Spawn success %j %j: signal = %j status = %j ",
        exec,
        argv,
        signal,
        status,
      );
      children.delete(child);
      resolve({
        status,
        signal,
        stdout:
          stdout === null
            ? null
            : concatBuffer(stdout).toString(options.encoding),
        stderr:
          stderr === null
            ? null
            : concatBuffer(stderr).toString(options.encoding),
      });
    });
    children.add(child);
  });

const { Error: Error$2 } = globalThis;

/* c8 ignore start */
const isNotEmptyString = (any) => any !== "";
/* c8 ignore stop */

const rankWin32Exec = (exec) => {
  if (exec.endsWith(".exe")) {
    return 2;
  } else if (exec.endsWith(".cmd")) {
    return 1;
  } else {
    return 0;
  }
};

const compareWin32Exec = (exec1, exec2) =>
  rankWin32Exec(exec2) - rankWin32Exec(exec1);

const pickWin32Exec = (execs) => {
  assert(
    execs.length > 0,
    "where succeed and returned an empty executable array",
    Error$2,
  );
  execs = execs.slice();
  execs.sort(compareWin32Exec);
  return execs[0];
};

/* c8 ignore start */
const whereAsync = async (exec, children) => {
  const { status, signal, stdout, stderr } = await spawnAsync$1(
    {
      exec: "where.exe",
      argv: [exec],
      options: {
        stdio: "pipe",
        encoding: "utf8",
      },
    },
    children,
  );
  assert(
    !logErrorWhen(
      status !== 0 || signal !== null,
      "Could not locate executable %j: %j >> %s",
      exec,
      { status, signal },
      stderr,
    ),
    "Could not locate executable",
    Error$2,
  );
  return pickWin32Exec(stdout.split("\r\n").filter(isNotEmptyString));
};
/* c8 ignore stop */

const spawnAsync = async (command, children) => {
  try {
    return await spawnAsync$1(command, children);
  } catch (error) {
    /* c8 ignore start */ if (
      hasOwnProperty(error, "code") &&
      error.code === "ENOENT" &&
      platform$1 === "win32"
    ) {
      logWarning(
        "Could not find executable %j, we will try to locate it using `where.exe`. Often, this is caused by a missing extension on Windows. For instance `npx jest` should be `npx.cmd jest`. Note that it is possible to provide a windows-specific command with `command-win32`.",
        command.exec,
      );
      return await spawnAsync$1(
        {
          ...command,
          exec: await whereAsync(command.exec, children),
        },
        children,
      );
    } /* c8 ignore stop */ else {
      throw error;
    }
  }
};

const { String: String$3, parseInt } = globalThis;

const partialx_ = (f, x1) => (x2) => f(x1, x2);
const partialx__ = (f, x1) => (x2, x3) => f(x1, x2, x3);
const partialxx_ = (f, x1, x2) => (x3) => f(x1, x2, x3);
const partialx___ = (f, x1) => (x2, x3, x4) => f(x1, x2, x3, x4);
const partialxx___ = (f, x1, x2) => (x3, x4, x5) =>
  f(x1, x2, x3, x4, x5);
const partialxxx___ = (f, x1, x2, x3) => (x4, x5, x6) =>
  f(x1, x2, x3, x4, x5, x6);
const partialxx____ = (f, x1, x2) => (x3, x4, x5, x6) =>
  f(x1, x2, x3, x4, x5, x6);
const partialxxx____ = (f, x1, x2, x3) => (x4, x5, x6, x7) =>
  f(x1, x2, x3, x4, x5, x6, x7);

const resolveHostPath = ({ name, port }, path) =>
  new URL$b(path, `http://${name}:${String$3(port)}`).href;

const parseHost = (host_string) => {
  const { hostname: name, port: port_string } = new URL$b(
    `http://${host_string}`,
  );
  return {
    name,
    port: port_string === "" ? 80 : parseInt(port_string),
  };
};

const toSocketAddress = (address) => {
  if (typeof address === "string") {
    return { path: address };
  } else if (typeof address === "object" && address !== null) {
    return { host: "localhost", port: address.port };
  } else {
    throw new InternalAppmapError("invalid server address");
  }
};

const { concat: concatBufferArray } = Buffer;

const bufferReadable = (readable, callback) => {
  const buffers = [];
  readable.on("data", (buffer) => {
    buffers.push(buffer);
  });
  readable.on("end", () => {
    callback(concatBufferArray(buffers));
  });
};

const {
  String: String$2,
  Reflect: { ownKeys: ownKeys$1 },
  JSON: { stringify: stringifyJSON$2 },
} = globalThis;

const { Parser: HtmlParser } = HtmlParser2;

const escape_sequence_mapping = {
  __proto__: null,
  "&": "&amp",
  "<": "&lt",
  ">": "&gt",
  '"': "&quot",
};

const escapeSpecialCharacter = (character) => {
  assert(
    hasOwnProperty(escape_sequence_mapping, character),
    "unexpected special character",
    InternalAppmapError,
  );
  return escape_sequence_mapping[character];
};

const escapeHtml = (string) =>
  string.replace(/[&<>"]/gu, escapeSpecialCharacter);

const escapeScriptTag = () => "<\\/script>";

const escapeJs = (string) => string.replace(/<\/script>/gu, escapeScriptTag);

const makeHashUrl = (url, { start, end }) => {
  const url_object = new URL$b(url);
  url_object.hash = `#${String$2(start)}-${String$2(end)}`;
  return url_object.href;
};

const extractScriptType = (attributes) =>
  hasOwnProperty(attributes, "type") ? attributes.type : "script";

const isInstrumentable = ({ external, type }) =>
  !external && (type === "script" || type === "module");

// It would be easier to consistently
// set the `type` attribute but jsdom
// does support it and ignore the
// entire script when `type` is present.
const toTypeAttribute = (type) => {
  if (type === "script") {
    return "";
  } else if (type === "module") {
    return ' type="module"';
  } /* c8 ignore start */ else {
    throw InternalAppmapError("invalid script type");
  } /* c8 ignore stop */
};

const instrumentHtml = (instrumentJs, prelude, { url, content }) => {
  const tokens = [];
  let has_head = false;
  let script = null;
  const parser = new HtmlParser({
    onopentag: (name, attributes) => {
      tokens.push(`<${escapeHtml(name)}`);
      for (const key of ownKeys$1(attributes)) {
        tokens.push(` ${escapeHtml(key)}="${escapeHtml(attributes[key])}"`);
      }
      tokens.push(">");
      if (name === "head") {
        if (has_head) {
          logWarning("Duplicate head tag in %j", url);
        } else {
          has_head = true;
          for (const { type, url, content } of prelude) {
            if (content === null) {
              assert(
                url !== null,
                "prelude file should either define a url or a content",
                InternalAppmapError,
              );
              tokens.push(
                `<script${toTypeAttribute(type)} src=${stringifyJSON$2(
                  url,
                )}></script>`,
              );
            } else {
              tokens.push(
                `<script${toTypeAttribute(type)}>${escapeJs(content)}</script>`,
              );
            }
          }
        }
      } else if (name === "script") {
        assert(
          script === null,
          "nested script tag in html",
          InternalAppmapError,
        );
        if (has_head) {
          script = {
            type: extractScriptType(attributes),
            external: hasOwnProperty(attributes, "src"),
            start: parser.startIndex,
            tokens: [],
            end: null,
          };
        } else {
          logWarning(
            "Not instrumenting script in %j because it appears before any head html tag",
            url,
          );
        }
      }
    },
    onprocessinginstruction: (_name, text) => {
      tokens.push(`<${escapeHtml(text)}>`);
    },
    oncomment: (comment) => {
      tokens.push(`<!--${escapeHtml(comment)}-->`);
    },
    ontext: (text) => {
      if (script === null) {
        tokens.push(escapeHtml(text));
      } else {
        script.tokens.push(text);
      }
    },
    onclosetag: (name) => {
      if (script !== null) {
        assert(
          name === "script",
          "expected script closing tag",
          InternalAppmapError,
        );
        script.end = parser.endIndex;
        tokens.push(
          isInstrumentable(script)
            ? escapeJs(
                instrumentJs({
                  type: script.type,
                  url: makeHashUrl(url, script),
                  content: script.tokens.join(""),
                }),
              )
            : // We do not need to escape the script content
              // because it is impossible for it to contain
              // `</script>` as it would have terminated
              // the tag.
              script.tokens.join(""),
        );
        script = null;
      }
      tokens.push(`</${escapeHtml(name)}>`);
    },
  });
  parser.end(content);
  assert(
    script === null,
    "unfinished script tag should have been completed by htmlparser2",
    InternalAppmapError,
  );
  return tokens.join("");
};

const { Error: Error$1, decodeURIComponent, URL: URL$1 } = globalThis;

const { from: toBuffer$2 } = Buffer;

const splitDataPath = (path) => {
  const index = path.indexOf(",");
  return {
    head: path.substring(0, index),
    body: path.substring(index + 1),
  };
};

const generateReadFile = (readFile) => (url) => {
  const url_obj = new URL$1(url);
  if (url_obj.protocol === "file:") {
    return readFile(url_obj, "utf8");
  } else if (url_obj.protocol === "data:") {
    const { head, body } = splitDataPath(url_obj.pathname);
    if (head.endsWith(";base64")) {
      logDebugWhen(
        !head.toLowerCase().includes(";charset=utf-8;") &&
          !head.toLowerCase().includes(";charset=utf8;"),
        "Data url is encoded as base64 and does not declare UTF-8 as its character encoding, will try to use UTF-8 anyway >> %s",
        url,
      );
      return toBuffer$2(body, "base64").toString("utf8");
    } else {
      return decodeURIComponent(body);
    }
  } else {
    // This file is meant to be used at the same
    //   abstraction level as a node library.
    // Hence, this is delibearately left as an unknown error.
    // ie: not an External/Internal AppmapError.
    throw new Error$1("unsupported protocol");
  }
};

const readFile = generateReadFile(readFileSync);

const {
  JSON: { parse: parseJSON$1 },
} = globalThis;

const extractSourcemapUrl = ({ url, content }) => {
  const parts = /\/\/[#@] sourceMappingURL=(.*)[\s]*$/u.exec(content);
  if (parts === null) {
    return null;
  } else {
    return toAbsoluteUrl(parts[1], url);
  }
};

const parseSourcemapJson = ({ url, content }) => {
  try {
    return parseJSON$1(content);
  } catch (error) {
    logWarning("Could not parse source map at %j >> %O", url, error);
    return null;
  }
};

const isSourcemapValid = ({ url, data }) => {
  try {
    validateSourceMap(data);
    return true;
  } catch (error) {
    logWarning("Invalid source map at %j >> %O", url, error);
    return false;
  }
};

const parseSourcemap = (file, base) => {
  const { url } = file;
  const data = parseSourcemapJson(file);
  if (data === null || !isSourcemapValid({ url, data })) {
    return null;
  } else {
    const {
      sourceRoot: root,
      sources: relatives,
      sourcesContent: contents,
      mappings: payload,
    } = {
      sourceRoot: null,
      sourcesContent: null,
      ...data,
    };
    if (!url.startsWith("data:")) {
      base = url;
    }
    if (root !== null && root !== "") {
      base = toDirectoryUrl(toAbsoluteUrl(root, url));
    }
    return {
      sources: relatives.map((relative, index) => ({
        url: toAbsoluteUrl(relative, base),
        content:
          contents === null || index >= contents.length
            ? null
            : contents[index],
      })),
      payload,
    };
  }
};

const compileSourcemap = (payload) => {
  let source_index = 0;
  let source_line = 0;
  let source_column = 0;
  return payload.split(";").map((group) => {
    if (group === "") {
      return [];
    } else {
      let generated_column = 0;
      return group.split(",").map((segment) => {
        const fields = decode(segment);
        /* c8 ignore start */ if (fields.length === 1) {
          return [(generated_column += fields[0])];
        } /* c8 ignore stop */ else {
          return [
            (generated_column += fields[0]),
            (source_index += fields[1]),
            (source_line += fields[2]),
            (source_column += fields[3]),
          ];
        }
      });
    }
  });
};

const mapPosition = (mapping, { line, column }) => {
  if (line > 0 && line <= mapping.length) {
    for (const fields of mapping[line - 1]) {
      if (fields[0] === column && fields.length >= 4) {
        const [, source_index, mapped_line, mapped_column] = fields;
        return {
          index: source_index,
          position: {
            line: mapped_line + 1,
            column: mapped_column,
          },
        };
      }
    }
    return null;
  } else {
    return null;
  }
};

const createSource = (
  { url, content },
  {
    packages: package_matcher_array,
    exclude: global_criteria,
    "default-package": default_package,
    "postmortem-function-exclusion": postmortem,
  },
) => {
  const {
    enabled,
    exclude: local_criteria,
    "source-type": source,
    parsing: plugins,
  } = lookupUrl(package_matcher_array, url, default_package);
  if (enabled) {
    return {
      postmortem,
      enabled: true,
      parsing: { source, plugins },
      criteria: [...local_criteria, ...global_criteria],
      url,
      content,
      hash: null,
      program: null,
      inner: null,
    };
  } else {
    return {
      postmortem,
      enabled: false,
      parsing: { source, plugins },
      criteria: [],
      url,
      content,
      hash: null,
      program: null,
      inner: null,
    };
  }
};

/////////////////////////
// Lazy Initialization //
/////////////////////////

const parseSource = (source) => {
  if (source.program === null) {
    const { url, content, parsing } = source;
    const program = parseEstree({ url, content }, parsing);
    source.program = program;
    return program;
  } else {
    return source.program;
  }
};

const digestSourceContent = (source) => {
  const { content } = source;
  if (source.hash === null && content !== null) {
    const hash = digest(content);
    source.hash = hash;
    return hash;
  } else {
    return source.hash;
  }
};

const toInnerSource = (source) => {
  if (source.inner === null) {
    const { url, content, criteria } = source;
    const program = parseSource(source);
    const inner = createSource$1({ url, content, program });
    applyExclusionCriteria(inner, criteria);
    source.inner = inner;
    return inner;
  } else {
    return source.inner;
  }
};

///////////
// Query //
///////////

const isSourceEnabled = ({ enabled }) => enabled;

const getSourceFile = ({ url, content }) => ({ url, content });

const isSourceContentRequired = ({ enabled, postmortem }) =>
  enabled && postmortem === false;

const isSourcePostmortemExclusion = ({
  postmortem,
  content,
  program,
}) => {
  if (content === null) {
    return true;
  } else if (typeof postmortem === "boolean") {
    return postmortem;
  } else {
    // If the program is already parsed,
    // it reduces of excluding functions here.
    return program === null;
  }
};

const resolveClosureLocation$1 = (source, position) => {
  const { enabled, url } = source;
  if (enabled) {
    if (isSourcePostmortemExclusion(source)) {
      return {
        url,
        hash: digestSourceContent(source),
        position,
      };
    } else {
      const maybe_resolved_position = resolveClosurePosition(
        toInnerSource(source),
        position,
      );
      if (
        maybe_resolved_position === null ||
        isClosurePositionExcluded(
          toInnerSource(source),
          maybe_resolved_position,
        )
      ) {
        return null;
      } else {
        return {
          url,
          hash: digestSourceContent(source),
          position: maybe_resolved_position,
        };
      }
    }
  } else {
    return null;
  }
};

const getUrl = ({ url }) => url;

const extractMissingUrlArray = (url, cache, configuration) => {
  if (cache.has(url)) {
    const content = cache.get(url);
    if (content === null) {
      return [];
    } else {
      const file = { url, content };
      const map_url = extractSourcemapUrl(file);
      if (map_url === null) {
        return [];
      } else {
        if (cache.has(map_url)) {
          const map_content = cache.get(map_url);
          if (map_content === null) {
            return [];
          } else {
            const map_file = {
              url: map_url,
              content: map_content,
            };
            const sourcemap = parseSourcemap(map_file, url);
            if (sourcemap === null) {
              return [];
            } else {
              const { sources } = sourcemap;
              return sources
                .filter(
                  ({ url, content }) =>
                    content === null &&
                    !cache.has(url) &&
                    isSourceContentRequired(
                      createSource({ url, content }, configuration),
                    ),
                )
                .map(getUrl);
            }
          }
        } else {
          return [map_url];
        }
      }
    }
  } else {
    return [url];
  }
};

const loadSourcemap = (file, cache, configuration) => {
  const map_url = extractSourcemapUrl(file);
  if (map_url === null) {
    return null;
  } else {
    const { url } = file;
    if (cache.has(map_url)) {
      const map_content = cache.get(map_url);
      if (map_content === null) {
        return null;
      } else {
        const map_file = {
          url: map_url,
          content: map_content,
        };
        const sourcemap = parseSourcemap(map_file, url);
        if (sourcemap === null) {
          return null;
        } else {
          const { sources, payload } = sourcemap;
          return {
            mapping: compileSourcemap(payload),
            sources: sources.map(({ url, content }) =>
              createSource(
                {
                  url,
                  content:
                    content === null && cache.has(url)
                      ? cache.get(url)
                      : content,
                },
                configuration,
              ),
            ),
          };
        }
      }
    } else {
      return null;
    }
  }
};

const createCodebase = (url, cache, configuration) => {
  assert(cache.has(url), "missing main content", InternalAppmapError);
  const content = cache.get(url);
  assert(
    !logErrorWhen(
      content === null,
      "Cannot not instrument file %j because it could not be loaded",
      url,
    ),
    "missing main content",
    ExternalAppmapError,
  );
  const file = { url, content };
  return {
    main: createSource(file, configuration),
    sourcemap: loadSourcemap(file, cache, configuration),
  };
};

const getEnabledSourceFileArray = ({ main, sourcemap }) =>
  (sourcemap === null ? [main] : sourcemap.sources)
    .filter(isSourceEnabled)
    .map(getSourceFile);

const getMainFile = ({ main }) => getSourceFile(main);

const parseMain = ({ main }) => parseSource(main);

const resolveClosureLocation = ({ main, sourcemap }, position) => {
  if (sourcemap === null) {
    return resolveClosureLocation$1(main, position);
  } else {
    const { sources, mapping } = sourcemap;
    const maybe_indexed_position = mapPosition(mapping, position);
    if (maybe_indexed_position === null) {
      // This is fine, it happens when compilation introduces new functions.
      // eg:
      // ```js
      //   var __importDefault = (this && this.__importDefault) || function (mod) {
      //     return (mod && mod.__esModule) ? mod : { "default": mod };
      //   };
      // ```
      return null;
    } else {
      const { index, position: mapped_position } = maybe_indexed_position;
      if (index >= 0 && index < sources.length) {
        return resolveClosureLocation$1(sources[index], mapped_position);
      } /* c8 ignore start */ else {
        logWarning(
          "Treating %j in %j as excluded because its mapped source index is out-of-range",
          position,
          getSourceFile(main).url,
        );
        return null;
      } /* c8 ignore stop */
    }
  }
};

const {
  Error,
  String: String$1,
  Array: { isArray },
  Object: { fromEntries },
  Reflect: { ownKeys },
} = globalThis;

//////////////////////////////
// Difficulties with groups //
//////////////////////////////

// import {createHook, executionAsyncId} from "async_hooks";
// createHook({}).enable();
// import {writeFileSync} from "fs";
// const {stdout:{fd}} = process;
// const log = (string) => writeFileSync(fd, `[${executionAsyncId()}] ${string}\n`);
// const logAwait = async (promise) => {
//   log("before");
//   try {
//     await promise;
//   } finally {
//     log("after");
//   }
// };
// const mainAsync = async () => {
//   log("begin");
//   try {
//     await logAwait(new Promise((resolve) => {
//       setTimeout(resolve, 1000, 123);
//     }));
//   } finally {
//     log("end");
//   }
// };
// await mainAsync();

// import {createHook, executionAsyncId} from "async_hooks";
// createHook({}).enable();
// import {writeFileSync} from "fs";
// const {stdout:{fd}} = process;
// const log = (string) => writeFileSync(fd, `[${executionAsyncId()}] ${string}\n`);
// function* logYield (result) {
//   log("before");
//   yield result;
//   log("after");
// };
// async function* main () {
//   log("begin");
//   yield* logYield(123);
//   log("end");
// }
// const iterator = main();
// iterator.next();
// iterator.next();

/////////////
// Builder //
/////////////

const makeProgram = (source, body) => ({
  type: "Program",
  sourceType: source,
  body,
});

const makeClosure = (
  type,
  asynchronous,
  generator,
  expression,
  id,
  params,
  body,
) => ({
  type,
  async: asynchronous,
  generator,
  expression,
  id,
  params,
  body,
});

const makeSequenceExpression = (nodes) => ({
  type: "SequenceExpression",
  expressions: nodes,
});

const makeStatement = (node) => ({
  type: "ExpressionStatement",
  expression: node,
});

const makeIfStatement = (node1, node2, node3) => ({
  type: "IfStatement",
  test: node1,
  consequent: node2,
  alternate: node3,
});

const makeBlockStatement = (nodes) => ({
  type: "BlockStatement",
  body: nodes,
});

const makeAwaitExpression = (node) => ({
  type: "AwaitExpression",
  argument: node,
});

const makeYieldExpression = (delegate, node) => ({
  type: "YieldExpression",
  delegate,
  argument: node,
});

const makeConditionalExpression = (node1, node2, node3) => ({
  type: "ConditionalExpression",
  test: node1,
  consequent: node2,
  alternate: node3,
});

const makeLogicalExpression = (operator, node1, node2) => ({
  type: "LogicalExpression",
  operator,
  left: node1,
  right: node2,
});

const makeCatchClause = (node1, node2) => ({
  type: "CatchClause",
  param: node1,
  body: node2,
});

const makeTryStatement = (node1, node2, node3) => ({
  type: "TryStatement",
  block: node1,
  handler: node2,
  finalizer: node3,
});

const makeRestElement = (node) => ({
  type: "RestElement",
  argument: node,
});

const makeUnaryExpression = (operator, node) => ({
  type: "UnaryExpression",
  prefix: true,
  operator,
  argument: node,
});

const makeBinaryExpression = (operator, node1, node2) => ({
  type: "BinaryExpression",
  operator,
  left: node1,
  right: node2,
});

const makeAssignmentExpression = (node1, node2) => ({
  type: "AssignmentExpression",
  operator: "=",
  left: node1,
  right: node2,
});

const makeArrayExpression = (nodes) => ({
  type: "ArrayExpression",
  elements: nodes,
});

const makeThisExpression = () => ({
  type: "ThisExpression",
});

const makeIdentifier = (name) => ({
  type: "Identifier",
  name,
});

const makeLiteral = (name) => ({
  type: "Literal",
  value: name,
});

const makeVariableDeclaration = (kind, nodes) => ({
  type: "VariableDeclaration",
  kind,
  declarations: nodes,
});

const makeThrowStatement = (node) => ({
  type: "ThrowStatement",
  argument: node,
});

const makeVariableDeclarator = (node1, node2) => ({
  type: "VariableDeclarator",
  id: node1,
  init: node2,
});

const makeCallExpression = (node, nodes) => ({
  type: "CallExpression",
  optional: false,
  callee: node,
  arguments: nodes,
});

const makeExpressionStatement = (node) => ({
  type: "ExpressionStatement",
  expression: node,
});

const makeRegularMemberExpression = (name1, name2) => ({
  type: "MemberExpression",
  optional: false,
  computed: false,
  object: makeIdentifier(name1),
  property: makeIdentifier(name2),
});

const makeReturnStatement = (argument) => ({
  type: "ReturnStatement",
  argument,
});

///////////////
// Component //
///////////////

const isJumpClosureNode = (node) => {
  if (node.type === "Program") {
    return node.sourceType === "module";
  } else if (
    node.type === "FunctionExpression" ||
    node.type === "FunctionDeclaration"
  ) {
    return node.async || node.generator;
  } else if (node.type === "ArrowFunctionExpression") {
    return node.async;
  } /* c8 ignore start */ else {
    throw new Error("unexpected closure node");
  } /* c8 ignore stop */
};

const isSubclassConstructor = (_node, parent, grand_parent) =>
  parent.type === "MethodDefinition" &&
  parent.kind === "constructor" &&
  grand_parent.superClass !== null;

const isEstreeKey = (key) => key !== "loc" && key !== "start" && key !== "end";

/* eslint-disable no-use-before-define */
const visitNode = (node, parent, grand_parent, closure, context) => {
  if (isArray(node)) {
    return node.map((node) =>
      visitNode(node, parent, grand_parent, closure, context),
    );
  } else if (
    typeof node === "object" &&
    node !== null &&
    hasOwnProperty(node, "type")
  ) {
    if (hasOwnProperty(instrumenters, node.type)) {
      const maybe_node = instrumenters[node.type](
        node,
        parent,
        grand_parent,
        closure,
        context,
      );
      return maybe_node === null
        ? visitGeneric(node, parent, grand_parent, closure, context)
        : maybe_node;
    } else {
      return visitGeneric(node, parent, grand_parent, closure, context);
    }
  } else {
    return node;
  }
};
/* eslint-enable no-use-before-define */

const visitGeneric = (node, parent, _grand_parent, closure, context) =>
  fromEntries(
    ownKeys(node)
      .filter(isEstreeKey)
      .map((key) => [
        key,
        visitNode(node[key], node, parent, closure, context),
      ]),
  );

const instrumentClosure = (node, parent, grand_parent, closure, context) => {
  const maybe_location = resolveClosureLocation(
    context.codebase,
    node.loc.start,
  );
  closure = {
    node,
    instrumented: context.apply !== null && maybe_location !== null,
  };
  if (closure.instrumented) {
    const location_string = stringifyLocation(maybe_location);
    return makeClosure(
      node.type,
      node.async,
      node.generator,
      false,
      mapMaybe(coalesce(node, "id", null), (child) =>
        visitNode(child, node, parent, closure, context),
      ),
      node.params.map((param, index) => {
        const pattern = makeIdentifier(
          `${context.apply}_ARGUMENT_${String$1(index)}`,
        );
        return param.type === "RestElement"
          ? makeRestElement(pattern)
          : pattern;
      }),
      makeBlockStatement([
        makeVariableDeclaration("var", [
          makeVariableDeclarator(
            makeIdentifier(`${context.apply}_BUNDLE_TAB`),
            makeCallExpression(
              makeRegularMemberExpression(context.apply, "getFreshTab"),
              [],
            ),
          ),
          makeVariableDeclarator(
            makeIdentifier(`${context.apply}_RESULT`),
            null,
          ),
          makeVariableDeclarator(
            makeIdentifier(`${context.apply}_DONE`),
            makeLiteral(false),
          ),
          ...(isJumpClosureNode(node)
            ? [
                makeVariableDeclarator(
                  makeIdentifier(`${context.apply}_JUMP`),
                  null,
                ),
                makeVariableDeclarator(
                  makeIdentifier(`${context.apply}_JUMP_TAB`),
                  makeLiteral(null),
                ),
              ]
            : []),
        ]),
        makeExpressionStatement(
          makeCallExpression(
            makeRegularMemberExpression(context.apply, "recordApply"),
            [
              makeIdentifier(`${context.apply}_BUNDLE_TAB`),
              makeLiteral(location_string),
              node.type === "ArrowFunctionExpression" ||
              isSubclassConstructor(node, parent, grand_parent)
                ? makeRegularMemberExpression(context.apply, "empty")
                : makeThisExpression(),
              makeArrayExpression(
                node.params.map((_param, index) =>
                  makeIdentifier(`${context.apply}_ARGUMENT_${String$1(index)}`),
                ),
              ),
            ],
          ),
        ),
        makeTryStatement(
          makeBlockStatement([
            ...(node.params.length === 0
              ? []
              : [
                  makeVariableDeclaration(
                    "var",
                    node.params.map((param, index) => {
                      if (param.type === "RestElement") {
                        param = param.argument;
                      }
                      // Special case for AssignmentPattern:
                      //
                      // function f (x = {}) {}
                      //
                      // function f (APPMAP_ARGUMENT_0) {
                      //   // does not work :(
                      //   var x = {} = APPMAP_ARGUMENT_0;
                      // }
                      if (param.type === "AssignmentPattern") {
                        return makeVariableDeclarator(
                          param.left,
                          makeConditionalExpression(
                            makeBinaryExpression(
                              "===",
                              makeIdentifier(
                                `${context.apply}_ARGUMENT_${String$1(index)}`,
                              ),
                              makeUnaryExpression("void", makeLiteral(0)),
                            ),
                            param.right,
                            makeIdentifier(
                              `${context.apply}_ARGUMENT_${String$1(index)}`,
                            ),
                          ),
                        );
                      } else {
                        return makeVariableDeclarator(
                          param,
                          makeIdentifier(
                            `${context.apply}_ARGUMENT_${String$1(index)}`,
                          ),
                        );
                      }
                    }),
                  ),
                ]),
            node.expression
              ? makeReturnStatement(
                  makeAssignmentExpression(
                    makeIdentifier(`${context.apply}_RESULT`),
                    visitNode(node.body, node, parent, closure, context),
                  ),
                )
              : visitNode(node.body, node, parent, closure, context),
          ]),
          makeCatchClause(
            makeIdentifier(`${context.apply}_ERROR`),
            makeBlockStatement([
              ...(isJumpClosureNode(node)
                ? [
                    makeIfStatement(
                      makeBinaryExpression(
                        "!==",
                        makeIdentifier(`${context.apply}_JUMP_TAB`),
                        makeLiteral(null),
                      ),
                      makeBlockStatement([
                        makeStatement(
                          makeCallExpression(
                            makeRegularMemberExpression(
                              context.apply,
                              "recordReject",
                            ),
                            [
                              makeIdentifier(`${context.apply}_JUMP_TAB`),
                              makeIdentifier(`${context.apply}_ERROR`),
                            ],
                          ),
                        ),
                        makeStatement(
                          makeAssignmentExpression(
                            makeIdentifier(`${context.apply}_JUMP_TAB`),
                            makeLiteral(null),
                          ),
                        ),
                      ]),
                      null,
                    ),
                  ]
                : []),
              makeExpressionStatement(
                makeAssignmentExpression(
                  makeIdentifier(`${context.apply}_DONE`),
                  makeLiteral(true),
                ),
              ),
              makeExpressionStatement(
                makeCallExpression(
                  makeRegularMemberExpression(context.apply, "recordThrow"),
                  [
                    makeIdentifier(`${context.apply}_BUNDLE_TAB`),
                    makeLiteral(location_string),
                    makeIdentifier(`${context.apply}_ERROR`),
                  ],
                ),
              ),
              makeThrowStatement(makeIdentifier(`${context.apply}_ERROR`)),
            ]),
          ),
          makeBlockStatement([
            ...(isJumpClosureNode(node)
              ? [
                  makeIfStatement(
                    makeBinaryExpression(
                      "!==",
                      makeIdentifier(`${context.apply}_JUMP_TAB`),
                      makeLiteral(null),
                    ),
                    makeBlockStatement([
                      makeStatement(
                        makeCallExpression(
                          makeRegularMemberExpression(
                            context.apply,
                            "recordResolve",
                          ),
                          [
                            makeIdentifier(`${context.apply}_JUMP_TAB`),
                            makeRegularMemberExpression(context.apply, "empty"),
                          ],
                        ),
                      ),
                      makeStatement(
                        makeAssignmentExpression(
                          makeIdentifier(`${context.apply}_JUMP_TAB`),
                          makeLiteral(null),
                        ),
                      ),
                    ]),
                    null,
                  ),
                ]
              : []),
            makeIfStatement(
              makeUnaryExpression("!", makeIdentifier(`${context.apply}_DONE`)),
              makeBlockStatement([
                makeExpressionStatement(
                  makeCallExpression(
                    makeRegularMemberExpression(context.apply, "recordReturn"),
                    [
                      makeIdentifier(`${context.apply}_BUNDLE_TAB`),
                      makeLiteral(location_string),
                      makeIdentifier(`${context.apply}_RESULT`),
                    ],
                  ),
                ),
              ]),
              null,
            ),
          ]),
        ),
      ]),
    );
  } else {
    return makeClosure(
      node.type,
      node.async,
      node.generator,
      node.expression,
      mapMaybe(node.id, (child) =>
        visitNode(child, node, parent, closure, context),
      ),
      node.params.map((param) =>
        visitNode(param, node, parent, closure, context),
      ),
      visitNode(node.body, node, parent, closure, context),
    );
  }
};

const compileInstrumentJumpExpression =
  (makeRecordJumpExpression, makeForwardJumpExpression) =>
  (node, parent, _grand_parent, closure, context) =>
    closure.instrumented
      ? makeSequenceExpression([
          makeAssignmentExpression(
            makeIdentifier(`${context.apply}_JUMP`),
            visitNode(node.argument, node, parent, closure, context),
          ),
          makeLogicalExpression(
            "||",
            makeBinaryExpression(
              "===",
              makeIdentifier(`${context.apply}_JUMP_TAB`),
              makeLiteral(null),
            ),
            makeIdentifier(`${context.apply}_APPMAP_JUMP_ASSERTION_VIOLATION`),
          ),
          makeAssignmentExpression(
            makeIdentifier(`${context.apply}_JUMP_TAB`),
            makeCallExpression(
              makeRegularMemberExpression(context.apply, "getFreshTab"),
              [],
            ),
          ),
          makeRecordJumpExpression(node, context.apply),
          makeAssignmentExpression(
            makeIdentifier(`${context.apply}_JUMP`),
            makeForwardJumpExpression(node, context.apply),
          ),
          makeCallExpression(
            makeRegularMemberExpression(context.apply, "recordResolve"),
            [
              makeIdentifier(`${context.apply}_JUMP_TAB`),
              makeIdentifier(`${context.apply}_JUMP`),
            ],
          ),
          makeAssignmentExpression(
            makeIdentifier(`${context.apply}_JUMP_TAB`),
            makeLiteral(null),
          ),
          makeIdentifier(`${context.apply}_JUMP`),
        ])
      : null;

const instrumenters = {
  AwaitExpression: compileInstrumentJumpExpression(
    (_node, namespace) =>
      makeCallExpression(
        makeRegularMemberExpression(namespace, "recordAwait"),
        [
          makeIdentifier(`${namespace}_JUMP_TAB`),
          makeIdentifier(`${namespace}_JUMP`),
        ],
      ),
    (_node, namespace) =>
      makeAwaitExpression(makeIdentifier(`${namespace}_JUMP`)),
  ),
  YieldExpression: compileInstrumentJumpExpression(
    ({ delegate }, namespace) =>
      makeCallExpression(
        makeRegularMemberExpression(namespace, "recordYield"),
        [
          makeIdentifier(`${namespace}_JUMP_TAB`),
          makeLiteral(delegate),
          makeIdentifier(`${namespace}_JUMP`),
        ],
      ),
    ({ delegate }, namespace) =>
      makeYieldExpression(delegate, makeIdentifier(`${namespace}_JUMP`)),
  ),
  ReturnStatement: (node, parent, _grand_parent, closure, context) =>
    closure.instrumented && node.argument !== null
      ? makeReturnStatement(
          makeAssignmentExpression(
            makeIdentifier(`${context.apply}_RESULT`),
            visitNode(node.argument, node, parent, closure, context),
          ),
        )
      : null,
  CallExpression: (node, parent, _grand_parent, closure, context) => {
    if (
      node.callee.type === "Identifier" &&
      context.eval.aliases.includes(node.callee.name) &&
      node.arguments.length > 0
    ) {
      return makeCallExpression(makeIdentifier(node.callee.name), [
        makeCallExpression(makeIdentifier(context.eval.hidden), [
          makeLiteral(context.url),
          makeLiteral(
            `${String$1(node.loc.start.line)}-${String$1(node.loc.start.column)}`,
          ),
          visitNode(node.arguments[0], node, parent, closure, context),
        ]),
        ...node.arguments
          .slice(1)
          .map((argument) =>
            visitNode(argument, node, parent, closure, context),
          ),
      ]);
    } else {
      return null;
    }
  },
  TryStatement: (node, parent, _grand_parent, closure, context) => {
    if (closure.instrumented && isJumpClosureNode(closure.node)) {
      return makeTryStatement(
        visitNode(node.block, node, parent, closure, context),
        makeCatchClause(
          makeIdentifier(`${context.apply}_ERROR`),
          makeBlockStatement([
            makeIfStatement(
              makeBinaryExpression(
                "!==",
                makeIdentifier(`${context.apply}_JUMP_TAB`),
                makeLiteral(null),
              ),
              makeBlockStatement([
                makeStatement(
                  makeCallExpression(
                    makeRegularMemberExpression(context.apply, "recordReject"),
                    [
                      makeIdentifier(`${context.apply}_JUMP_TAB`),
                      makeIdentifier(`${context.apply}_ERROR`),
                    ],
                  ),
                ),
                makeStatement(
                  makeAssignmentExpression(
                    makeIdentifier(`${context.apply}_JUMP_TAB`),
                    makeLiteral(null),
                  ),
                ),
              ]),
              null,
            ),
            ...(node.handler === null
              ? []
              : [
                  ...(node.handler.param === null
                    ? []
                    : [
                        makeVariableDeclaration("let", [
                          makeVariableDeclarator(
                            visitNode(
                              node.handler.param,
                              node.handler,
                              node,
                              closure,
                              context,
                            ),
                            makeIdentifier(`${context.apply}_ERROR`),
                          ),
                        ]),
                      ]),
                  visitNode(
                    node.handler.body,
                    node.handler,
                    node,
                    closure,
                    context,
                  ),
                ]),
          ]),
        ),
        makeBlockStatement([
          makeIfStatement(
            makeBinaryExpression(
              "!==",
              makeIdentifier(`${context.apply}_JUMP_TAB`),
              makeLiteral(null),
            ),
            makeBlockStatement([
              makeStatement(
                makeCallExpression(
                  makeRegularMemberExpression(context.apply, "recordResolve"),
                  [
                    makeIdentifier(`${context.apply}_JUMP_TAB`),
                    makeRegularMemberExpression(context.apply, "empty"),
                  ],
                ),
              ),
              makeStatement(
                makeAssignmentExpression(
                  makeIdentifier(`${context.apply}_JUMP_TAB`),
                  makeLiteral(null),
                ),
              ),
            ]),
            null,
          ),
          ...(node.finalizer === null
            ? []
            : [visitNode(node.finalizer, node, parent, closure, context)]),
        ]),
      );
    } else {
      return null;
    }
  },
  Identifier: (node, _parent, _grand_parent, _closure, context) => {
    assert(
      !logErrorWhen(
        node.name.startsWith(context.apply),
        "Identifier collision detected at %j line %j column %j >> identifier should not start with %j, got: %j",
        context.url,
        node.loc.start.line,
        node.loc.start.column,
        context.apply,
        node.name,
      ),
      "Identifier collision",
      ExternalAppmapError,
    );
    return null;
  },
  Program: (node, parent, _grand_parent, closure, context) =>
    closure.instrumented && node.sourceType === "module"
      ? makeProgram("module", [
          makeVariableDeclaration("let", [
            makeVariableDeclarator(
              makeIdentifier(`${context.apply}_BUNDLE_TAB`),
              makeCallExpression(
                makeRegularMemberExpression(context.apply, "getFreshTab"),
                [],
              ),
            ),
            makeVariableDeclarator(
              makeIdentifier(`${context.apply}_JUMP`),
              null,
            ),
            makeVariableDeclarator(
              makeIdentifier(`${context.apply}_JUMP_TAB`),
              makeLiteral(null),
            ),
          ]),
          ...node.body.map((child) =>
            visitNode(child, node, parent, closure, context),
          ),
        ])
      : null,
  FunctionExpression: instrumentClosure,
  FunctionDeclaration: instrumentClosure,
  ArrowFunctionExpression: instrumentClosure,
};

const initial_parent = { type: "File" };

const initial_grand_parent = { type: "Root" };

const visit = (node, context) => {
  assert(
    node.type === "Program",
    "expected program as top level estree node",
    InternalAppmapError,
  );
  // Top level async jump only present in module.
  // Avoid poluting global scope in script.
  return visitNode(
    node,
    initial_parent,
    initial_grand_parent,
    {
      node,
      instrumented: context.apply !== null && node.sourceType === "module",
    },
    context,
  );
};

const { generate: generateEstree } = Astring;

const instrument = (url, cache, configuration) => {
  const codebase = createCodebase(url, cache, configuration);
  const files = getEnabledSourceFileArray(codebase);
  if (files.length === 0) {
    logDebug("*Not* recording file %j", url);
    return {
      ...getMainFile(codebase),
      sources: [],
    };
  } else {
    logDebug("Recording file %j", url);
    return {
      url,
      content: generateEstree(
        visit(parseMain(codebase), {
          url,
          eval: configuration.hooks.eval,
          apply: configuration.hooks.apply,
          codebase,
        }),
      ),
      sources: files,
    };
  }
};

const { Map: Map$1 } = globalThis;

const readFileSafe = (url, readFile) => {
  try {
    return readFile(url);
  } catch (error) {
    logWarning("Could not read file %j >> %O", url, error);
    return null;
  }
};

const instrumentInject = (url, content, configuration, readFile) => {
  const cache = new Map$1(content === null ? [] : [[url, content]]);
  while (true) {
    const urls = extractMissingUrlArray(url, cache, configuration);
    if (urls.length === 0) {
      return instrument(url, cache, configuration);
    } else {
      for (const url of urls) {
        cache.set(url, readFileSafe(url, readFile));
      }
    }
  }
};

const instrumentJs = (configuration, backend, { url, content }) => {
  const { sources, content: instrumented_content } = instrumentInject(
    url,
    content,
    configuration,
    readFile,
  );
  for (const { url, content } of sources) {
    sendBackend(backend, {
      type: "source",
      url,
      content,
    });
  }
  return instrumented_content;
};

const { from: toBuffer$1 } = Buffer;

const forwardRequest = (host, inc_req, callback) => {
  let done = false;
  /* c8 ignore start */
  inc_req.on("error", (error) => {
    if (!done) {
      done = true;
      callback(error, null);
    }
  });
  /* c8 ignore stop */
  const out_req = request({
    host: host.name,
    port: host.port,
    method: inc_req.method,
    path: inc_req.url,
    headers: inc_req.headers,
  });
  /* c8 ignore start */
  out_req.on("error", (error) => {
    if (!done) {
      done = true;
      callback(error, null);
    }
  });
  /* c8 ignore stop */
  out_req.on("response", (res) => {
    if (!done) {
      done = true;
      callback(null, res);
    }
  });
  inc_req.pipe(out_req);
};

const forwardResponse = (inc_res, out_res) => {
  out_res.writeHead(inc_res.statusCode, inc_res.statusMessage, inc_res.headers);
  inc_res.pipe(out_res);
};

const stringifyHead = ({
  method,
  url,
  httpVersion: version,
  rawHeaders: headers,
}) => {
  const chunks = [];
  chunks.push(`${method} ${url} HTTP/${version}`);
  for (let index = 0; index < headers.length; index += 2) {
    chunks.push(`${headers[index]}: ${headers[index + 1]}`);
  }
  chunks.push("");
  chunks.push("");
  return chunks.join("\r\n");
};

const forwardSpecial = (host, req, socket, head) => {
  const forward_socket = new Socket();
  /* c8 ignore start */
  socket.on("error", (error) => {
    logWarning(
      "error on socket %j >> %s %s %j >> %o",
      host,
      req.method,
      req.url,
      req.headers,
      error,
    );
    forward_socket.destroy();
  });
  forward_socket.on("error", (error) => {
    logWarning(
      "error on forward socket %j >> %s %s %j >> %o",
      host,
      req.method,
      req.url,
      req.headers,
      error,
    );
    socket.destroy();
  });
  /* c8 ignore stop */
  forward_socket.connect(host.port, host.name);
  forward_socket.on("connect", () => {
    forward_socket.write(toBuffer$1(stringifyHead(req), "utf8"));
    forward_socket.write(head);
    socket.pipe(forward_socket);
    forward_socket.pipe(socket);
  });
};

const forwardUpgrade = forwardSpecial;

const forwardConnect = forwardSpecial;

const {
  JSON: { stringify: stringifyJSON$1, parse: parseJSON },
} = globalThis;

const { from: toBuffer } = Buffer;

// https://www.ietf.org/rfc/rfc9239.html#section-6
// https://www.iana.org/assignments/media-types/media-types.xhtml
const isJavascriptContentType = (header) =>
  header.startsWith("text/javascript") ||
  header.startsWith("text/ecmascript") ||
  header.startsWith("application/javascript") ||
  header.startsWith("application/ecmascript");

const isHtmlContentType = (header) => header.startsWith("text/html");

const recorder_browser_content = readFileSync(
  new URL$b("dist/bundles/recorder-browser.mjs", self_directory),
  "utf8",
);

const getContentTypeCharset = (header) => {
  logDebugWhen(
    !header.toLowerCase().includes("charset=utf-8"),
    "http response content-type header does not declare utf8 encoding but will try to use it anyway, got: %j",
    header,
  );
  return "utf8";
};

const interceptRequest = (
  configuration,
  backend,
  host,
  inc_req,
  out_res,
) => {
  logDebug(
    "intercept request to %j >> %s %s %j",
    host,
    inc_req.method,
    inc_req.url,
    inc_req.headers,
  );
  assert(
    inc_req.url !== `/${configuration["http-switch"]}`,
    "unexpected regular request related to appmap",
    InternalAppmapError,
  );
  forwardRequest(host, inc_req, (error, inc_res) => {
    /* c8 ignore start */ if (error !== null) {
      logWarning(
        "error on request to %j >> %s %s %j >> %o",
        host,
        inc_req.method,
        inc_req.url,
        inc_req.headers,
        error,
      );
      out_res.writeHead(500);
      out_res.end();
    } /* c8 ignore stop */ else {
      logDebug(
        "intercept response from %j >> %j %s %j",
        host,
        inc_res.statusCode,
        inc_res.statusMessage,
        inc_res.headers,
      );
      if (
        hasOwnProperty(inc_res.headers, "content-type") &&
        isHtmlContentType(inc_res.headers["content-type"])
      ) {
        bufferReadable(inc_res, (buffer) => {
          const encoding = getContentTypeCharset(
            inc_res.headers["content-type"],
          );
          const body = toBuffer(
            instrumentHtml(
              partialxx_(instrumentJs, configuration, backend),
              [
                {
                  type: "script",
                  url: null,
                  content: `
                    "use strict";
                    ((() => {
                      if (globalThis.__APPMAP_CONFIGURATION__ === void 0) {
                        globalThis.__APPMAP_CONFIGURATION__ = ${stringifyJSON$1(
                          configuration,
                        )};
                        globalThis.__APPMAP_LOG_LEVEL__ = ${stringifyJSON$1(
                          configuration.log.level,
                        )};
                        ${recorder_browser_content}
                      }
                    }) ());
                  `,
                },
              ],
              {
                url: resolveHostPath(host, inc_req.url),
                content: buffer.toString(encoding),
              },
            ),
            encoding,
          );
          out_res.writeHead(inc_res.statusCode, inc_res.statusMessage, {
            ...inc_res.headers,
            "content-length": body.length,
          });
          out_res.end(body);
        });
      } else if (
        hasOwnProperty(inc_res.headers, "content-type") &&
        isJavascriptContentType(inc_res.headers["content-type"])
      ) {
        bufferReadable(inc_res, (buffer) => {
          const encoding = getContentTypeCharset(
            inc_res.headers["content-type"],
          );
          const body = toBuffer(
            instrumentJs(configuration, backend, {
              url: resolveHostPath(host, inc_req.url),
              content: buffer.toString(encoding),
            }),
            encoding,
          );
          out_res.writeHead(inc_res.statusCode, inc_res.statusMessage, {
            ...inc_res.headers,
            "content-length": body.length,
          });
          out_res.end(body);
        });
      } else {
        forwardResponse(inc_res, out_res);
      }
    }
  });
};

const interceptUpgrade = (
  configuration,
  backend,
  wss,
  host,
  req,
  socket,
  head,
) => {
  logDebug(
    "intercept upgrade to %j >> %s %s %j",
    host,
    req.method,
    req.url,
    req.headers,
  );
  if (req.url === `/${configuration["http-switch"]}`) {
    /* c8 ignore start */
    socket.on("error", (error) => {
      logWarning(
        "appmap socket error %j >> %s %s %j >> %o",
        host,
        req.method,
        req.url,
        req.headers,
        error,
      );
    });
    /* c8 ignore stop */
    wss.handleUpgrade(req, socket, head, (ws) => {
      ws.on("message", (data) => {
        for (const message of inflate(parseJSON(data.toString("utf8")))) {
          sendBackend(backend, message);
        }
      });
      /* c8 ignore start */
      ws.on("error", (error) => {
        logWarning(
          "appmap websocket error %j >> %s %s %j >> %o",
          host,
          req.method,
          req.url,
          req.headers,
          error,
        );
      });
    });
    /* c8 ignore stop */
  } else {
    forwardUpgrade(host, req, socket, head);
  }
};

const interceptConnect = (
  configuration,
  _backend,
  host,
  req,
  socket,
  head,
) => {
  logDebug(
    "intercept connect to %j >> %s %s %j",
    host,
    req.method,
    req.url,
    req.headers,
  );
  assert(
    req.url !== `/${configuration["http-switch"]}`,
    "unexpected connect request related to appmap",
    InternalAppmapError,
  );
  forwardConnect(host, req, socket, head);
};

const HEAD = [
  "HTTP/1.1 200 Connection Established",
  "Proxy-agent: AppmapProxy",
  "",
  "",
].join("\r\n");

const getFreshPort = () => {
  /* c8 ignore start */
  if (platform$1 === "win32") {
    return 0;
  } else {
    return `${tmpdir()}/${getUuid()}}`;
  }
  /* c8 ignore stop */
};

const forge = (servers, pool, host_string, handlers) => {
  if (servers.has(host_string)) {
    return servers.get(host_string);
  } else {
    const host = parseHost(host_string);
    const server = createServer$1();
    server.on("connection", partialx_(addPool, pool));
    server.on("request", partialx__(handlers.request, host));
    server.on("upgrade", partialx___(handlers.upgrade, host));
    server.on("connect", partialx___(handlers.connect, host));
    server.listen(getFreshPort());
    servers.set(host_string, server);
    return server;
  }
};

const requestProxy = (request, req, res) => {
  request(parseHost(req.headers.host), req, res);
};

const upgradeProxy = (upgrade, req, socket, head) => {
  upgrade(parseHost(req.headers.host), req, socket, head);
};

const connect = (server, req, socket, head) => {
  const forward_socket = new Socket();
  /* c8 ignore start */
  forward_socket.on("error", () => {
    socket.destroy();
  });
  socket.on("error", () => {
    forward_socket.destroy();
  });
  forward_socket.on("error", (error) => {
    logWarning(
      "error on forward proxy socket >> %s %s %j >> %o",
      req.method,
      req.url,
      req.headers,
      error,
    );
  });
  /* c8 ignore stop */
  forward_socket.connect(toSocketAddress(server.address()));
  forward_socket.on("connect", () => {
    socket.write(HEAD);
    forward_socket.write(head);
    socket.pipe(forward_socket);
    forward_socket.pipe(socket);
  });
};

const connectProxy = (handlers, servers, pool, req, socket, head) => {
  logDebug("proxy CONNECT %s %j", req.url, req.headers);
  /* c8 ignore start */
  socket.on("error", (error) => {
    logWarning(
      "error on proxy socket >> %s %s %j >> %o",
      req.method,
      req.url,
      req.headers,
      error,
    );
  });
  /* c8 ignore stop */
  const { url: host_string } = req;
  const server = forge(servers, pool, host_string, handlers);
  /* c8 ignore start */
  if (server.listening) {
    connect(server, req, socket, head);
  } else {
    server.on("listening", () => {
      connect(server, req, socket, head);
    });
  }
  /* c8 ignore stop */
};

const { Promise: Promise$2, Map } = globalThis;

const openMitmAsync = async (configuration, backend) => {
  assert(
    configuration["proxy-port"] !== null,
    "cannot open mitm because it is disabled",
    InternalAppmapError,
  );
  const wss = new WebSocketServer({ noServer: true });
  const proxy = createServer$1();
  const handlers = {
    request: partialxx___(interceptRequest, configuration, backend),
    connect: partialxx____(interceptConnect, configuration, backend),
    upgrade: partialxxx____(interceptUpgrade, configuration, backend, wss),
  };
  const pool = createPool();
  const servers = new Map();
  proxy.on("connection", partialx_(addPool, pool));
  proxy.on("request", partialx__(requestProxy, handlers.request));
  proxy.on("upgrade", partialx___(upgradeProxy, handlers.upgrade));
  proxy.on("connect", partialxxx___(connectProxy, handlers, servers, pool));
  proxy.listen(configuration["proxy-port"]);
  await new Promise$2((resolve, reject) => {
    proxy.on("error", reject);
    proxy.on("listening", resolve);
  });
  return { proxy, servers, pool };
};

const getMitmPort = ({ proxy }) => proxy.address().port;

const closeMitmAsync = async ({ proxy, servers, pool }) => {
  const promises = [proxy, ...servers.values()].map((server) => {
    server.close();
    return new Promise$2((resolve, reject) => {
      server.on("error", reject);
      server.on("close", resolve);
    });
  });
  closePool(pool, 1000);
  await Promise$2.all(promises);
};

const {
  Promise: Promise$1,
  String,
  URL,
  Set,
  setTimeout,
  JSON: { stringify: stringifyJSON },
} = globalThis;

const FLUSH_TIMEOUT = 1000;
const ABRUPT_TIMEOUT = 1000;

const isCommandNonNull = ({ command }) => command !== null;

const refreshUrl = (urls, url) => {
  const basename = getUrlBasename(url);
  const extension = getUrlExtension(url);
  let index = 0;
  while (urls.has(url)) {
    index += 1;
    url = toAbsoluteUrl(`${basename}-${String(index)}${extension}`, url);
  }
  urls.add(url);
  return url;
};

const flushBackendAsync = async (urls, backend, abrupt) => {
  let trace = compileBackendAvailableTrack(backend, abrupt);
  while (trace !== null) {
    const { url, content } = trace;
    const fresh_url = refreshUrl(urls, url);
    await mkdir(new URL(".", fresh_url), { recursive: true });
    await writeFile(
      new URL(fresh_url),
      stringifyJSON(content, null, 2),
      "utf8",
    );
    trace = compileBackendAvailableTrack(backend, abrupt);
  }
};

const describeCommand = ({ source, tokens }) => source ?? tokens;

const runConfigurationAsync = async (configuration, env, children) => {
  configuration = resolveConfigurationAutomatedRecorder(configuration, env);
  const command = await compileConfigurationCommandAsync(configuration, env);
  try {
    return await spawnAsync(command, children);
  } catch (error) {
    logError(
      "Child error %j >> %O",
      describeCommand(configuration.command),
      error,
    );
    throw new ExternalAppmapError("Failed to spawn child process");
  }
};

const mainAsync = async (process, configuration) => {
  configuration = resolveConfigurationRepository(configuration);
  const { env } = process;
  const children = new Set();
  let done = false;
  process.on("SIGINT", () => {
    killAllAsync(children);
    done = true;
  });
  const urls = new Set();
  const backend = createBackend(configuration);
  const receptor = await openReceptorAsync(configuration, backend);
  const ports = {
    "trace-port": getReceptorTracePort(receptor),
    "track-port": getReceptorTrackPort(receptor),
  };
  const maybe_mitm =
    configuration["proxy-port"] === null
      ? null
      : await openMitmAsync(configuration, backend);
  if (maybe_mitm !== null) {
    logInfo("proxy listening to %j", getMitmPort(maybe_mitm));
  }
  const flushing = (async () => {
    while (!done) {
      await flushBackendAsync(urls, backend, false);
      if (!done) {
        await new Promise$1((resolve) => {
          setTimeout(resolve, FLUSH_TIMEOUT);
        });
      }
    }
    if (!isBackendEmpty(backend)) {
      await new Promise$1((resolve) => {
        setTimeout(resolve, ABRUPT_TIMEOUT);
      });
      await flushBackendAsync(urls, backend, true);
    }
  })();
  const configurations = [
    configuration,
    ...getConfigurationScenarios(configuration),
  ]
    .map(pickPlatformSpecificCommand)
    .filter(isCommandNonNull)
    .map((configuration) => extendConfigurationPort(configuration, ports));
  const { length } = configurations;
  let aggregate_status = 0;
  if (length === 0) {
    logInfo(
      "Appmap server listening to client connections at: %j",
      ports["trace-port"],
    );
    logInfo(
      "Appmap server listening to remote recording requests at: %j",
      ports["track-port"],
    );
    logInfo("Waiting for SIGINT to stop ...");
  } else if (length === 1) {
    const configuration = configurations[0];
    logInfo("Spawning %j ...", describeCommand(configuration.command));
    logInfo("Send SIGINT to gracefully exit");
    const { signal, status } = await runConfigurationAsync(
      configuration,
      env,
      children,
    );
    /* c8 ignore start */
    if (signal !== null) {
      logInfo("Killed with: %s", signal);
      aggregate_status = 1;
    } else {
      logInfo("Exited with: %j", status);
      aggregate_status = status;
    }
    /* c8 ignore stop */
    done = true;
  } else {
    logInfo("Spawning %j processes sequentially ...", length);
    logInfo("Send SIGINT to gracefully exit");
    const summary = [];
    for (let index = 0; index < length; index += 1) {
      if (!done) {
        const configuration = configurations[index];
        const description = describeCommand(configuration.command);
        logInfo("Spawning %j [%j/%j] ...", description, index + 1, length);
        const { signal, status } = await runConfigurationAsync(
          configurations[index],
          env,
          children,
        );
        summary.push({ description, signal, status });
        /* c8 ignore start */
        if (signal !== null) {
          logInfo("Killed with: %s", signal);
          aggregate_status = 1;
        } else {
          logInfo("Exited with: %j", status);
          if (status !== 0) {
            aggregate_status = 1;
          }
        }
        /* c8 ignore stop */
      }
    }
    logInfo("Summary:");
    for (const { description, signal, status } of summary) {
      logInfo("%j >> %j", description, signal === null ? status : signal);
    }
    done = true;
  }
  await flushing;
  if (maybe_mitm !== null) {
    await closeMitmAsync(maybe_mitm);
  }
  await closeReceptorAsync(receptor);
  return aggregate_status;
};

export { mainAsync };
